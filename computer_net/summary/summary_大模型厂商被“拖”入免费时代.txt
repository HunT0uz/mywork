标题: 大模型厂商被“拖”入免费时代
链接: https://baijiahao.baidu.com/s?id=1799658327958926823&wfr=spider&for=pc
总结: 文 | 正见TrueView，作者 | 马万言当前除了传统电商业务被卷回消费者补贴的旧轨，“新贵风口”大模型领域同样掀起了价格战。5月15日，字节跳动正式对外发布豆包大模型，以大幅低于行业价格的商业定价，打响了国内AI大模型的首波价格战。接连几天内，幻方量化DeepSeek-V2、智谱AIGLM-3等相继宣布大幅降价大模型API调用价格。如此激烈的竞争之下，阿里云也于今日发布了通义千问GPT-4级主力模型Qwen-Long，API输入价格从0.02元/千tokens降至0.0005元/千tokens，直降97%。仅隔几个小时，百度更是宣布文心大模型的两款主力模型ENIRE Speed、ENIRE Lite全面免费，即刻生效。短短一天内，大模型价格战便从“厘时代”卷至了免费时代。从大厂至明星创业AI公司，低价已成为AI大模型市场的“第一吸引力法则”，客户开发拓展、市场用户教育借此铺开，产业快速迈向下一发展阶段。在火山引擎原动力大会上，总裁谭待重点披露了豆包大模型的商业化价格。对比国内外目前最新的32K主力模型，GPT4价格约为0.42元/千tokens，百度文心一言和降价前的阿里通义千问2.5价格均接近0.12元/千tokens，而豆包通用模型pro-32k版模型推理输入价格仅为0.0008元/千tokens，比行业低99.3%。极具优势与竞争力的定价策略一旦落地，对同业厂商的冲击可想而知。通义千问作为对比参照之一，也是不得不拿出更大“诚意”，不仅喊出“击穿地心式降价”，并同样拿出主力模型参与竞争。阿里云此次降价涵盖通义千问九款闭源及开源模型，包括目前百炼平台上调用量最大、性能对标GPT-4的模型Qwen-plus，以及旗舰款大模型Qwen-max，性能在权威基准OpenCompass上与GPT-4-turbo持平，其API输入价格也大幅降低。事实上，腾讯混元大模型的价格也在豆包大模型定价发布后明显降低。5月14日也就是豆包大模型发布的前一日，腾讯云官网显示混元大模型标准版（hunyuan-standard的前身）和高级版（hunyuan-pro的前身）的模型推理输入价格分别为0.012元/千tokens和0.12元/千tokens。5月17日，腾讯云生成式AI产业应用峰会召开，腾讯云在宣布混元大模型多个版本模型实现升级，虽全程没有公开介绍价格，但官网显示窗口尺寸为32K的hunyuan-standard模型和hunyuan-pro模型，模型推理输入价格分别为0.0069元/千tokens和0.069元/千tokens，两者均为刊例价的6.9折。相对于国内仅有6%的AIGC用户渗透率与普通用户的token使用量，有行业人士认为目前国内AI厂商核心争夺的是企业级市场，以及企业上云预算。谭待曾举例，企业要想用AI做一项创新，至少要消耗100亿token。“今年大模型能力提升，应用是很重要的环节，我们判断，在未来一年，大模型将在越来越多的企业场景从POC阶段走到真实的生产系统。”火山引擎是字节跳动旗下的云服务平台，以豆包大模型为打开企业创新需求的切入口，实施降价策略，将“企业AI创新成本从80万元将至8000元”作为重磅“弹药”抢占客户，从而推广、带动云服务增长，合乎商业曲线。阿里云也在回应本次通义千问降价的基本情况时表示，开源模型云上调用的成本远低于私有化部署。一般情况下，自建集群需要考虑的成本有集群硬件采购、软件部署、网络费用、电费，及硬件折旧、人力成本等，如果出现计算资源闲置或超载等情况，还需要付出额外成本；而在云上调用大模型API真正实现了随用随取，按需使用。以使用Qwen-72B开源模型、每月1亿token用量为例，在阿里云百炼上直接调用API每月仅需600元，私有化部署的成本平均每月超一万元。无论是业务关联性还是定价策略，国内AI大模型市场“会不会像云计算一样，价格战也打了，最后却一地鸡毛”成为新的顾虑和讨论点。根据火山引擎公布的价格计算，一元钱能买到豆包主力模型125万tokens，大约是200万个汉字，相当于三本《三国演义》。今日阿里云便打出“1元可以买200万tokens，相当于5本《新华字典》文字量”的应对牌，火药味十足。相似的一幕也曾在云计算市场上演。2023年4月，阿里云曾对核心产品价格全线下调15％－50％，腾讯云、京东云、移动云等随后跟进，降价力度大且涉及厂商多。2024年2月29日上午，阿里云再次宣布下调价格，对100余款核心产品平均降价20%，当晚京东云便宣布从次日起针对特定云服务商开启比价活动，并称“随便降，比到底!”。当时面对各界对于价格战的猜测与疑问，阿里云资深副总裁刘伟光曾表示，“云计算每经历一段时间的技术积累，都会产生新的规模效应和新的技术红利”。大模型降价引发的疑问与产生的应对也十分相似。谭待表示，“豆包模型的超低定价，来源于我们有信心用技术手段优化成本，而不是补贴或是打价格战争夺市场份额。”他认为，“羊毛出在猪身上”在企业市场行不通，技术驱动的极致性价比才能真正创造价值。据了解，火山引擎主要通过模型结构的优化、工程上从传统的单机推理变为分布式推理，以及把不同负载的推理进行混合调度等方式，带来超预期的降本效果。阿里云同样将此次大幅度降价归结于公共云技术红利和规模效应带来的巨大成本和性能优势。阿里云从模型和AI基础设施两个层面不断优化，追求极致的推理成本和性能。例如，阿里云基于自研的异构芯片互联、高性能网络HPN7.0、高性能存储CPFS、人工智能平台PAI等核心技术和产品，构建了极致弹性的AI算力调度系统，结合百炼分布式推理加速引擎，大幅压缩了模型推理成本，并加快模型推理速度。对于AI市场而言，低价策略显然有助于降低企业使用AI服务的门槛，加快推动AI技术的普及和应用，但也必然导致市场格局的重塑，促使其他厂商也采取降价策略，以维持市场竞争力。随着价格战的持续，国内AI大模型产业格局和市场秩序将面临更多变数，对于模型层的服务厂商们也提出了更严苛的竞争力构建要求，尤其是创业型企业，新开启的大模型“圈地战争”，恐怕无法留给其充足的发展窗口期。举报/反馈
关键词: AI大模型, 价格战,  豆包大模型
AI技术: AI大模型, 豆包大模型, 通义千问GPT-4级主力模型Qwen-Long
行业: 电商, AI大模型, 云计算
重大事件摘要: 这篇文章报道了中国AI大模型市场的价格战，以及各大厂商如何通过降价策略来争夺市场份额。以下是文章中提到的重大事件：

1. **字节跳动发布豆包大模型**：5月15日，字节跳动发布了豆包大模型，以低于行业价格的商业定价打响了国内AI大模型的首波价格战。

2. **其他厂商跟进降价**：紧接着，幻方量化DeepSeek-V2、智谱AIGLM-3等也宣布大幅降价大模型API调用价格。

3. **阿里云降价**：阿里云发布通义千问GPT-4级主力模型Qwen-Long，API输入价格从0.02元/千tokens降至0.0005元/千tokens，降幅达97%。

4. **百度免费开放文心大模型**：百度宣布文心大模型的两款主力模型ENIRE Speed、ENIRE Lite全面免费，即刻生效。

5. **腾讯云降价**：腾讯云在豆包大模型发布后，也降低了混元大模型的价格，标准版和高级版的模型推理输入价格分别降低了6.9折。

6. **企业级市场争夺**：文章指出，目前国内AI厂商核心争夺的是企业级市场，以及企业上云预算。

7. **技术驱动降低成本**：火山引擎和阿里云都表示，他们的降价是基于技术手段优化成本，而不是通过补贴或价格战来争夺市场份额。

8. **市场格局重塑**：低价策略有助于降低企业使用AI服务的门槛，推动AI技术的普及和应用，但也会导致市场格局的重塑，促使其他厂商采取降价策略以维持竞争力。

这些事件表明，中国AI大模型市场正在经历一场激烈的价格竞争，各大厂商都在通过降价策略来吸引客户，抢占市场份额。同时，这也反映了AI技术的快速发展和市场对AI服务需求的增加。
