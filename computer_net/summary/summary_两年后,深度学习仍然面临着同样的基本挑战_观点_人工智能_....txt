标题: 两年后,深度学习仍然面临着同样的基本挑战_观点_人工智能_...
链接: http://www.baidu.com/link?url=0PIKF-1byHkeXDJEdbKeXdk9t2nqQdvGay6T8lsB0HQqrm120w-3kUGw83mKUfQCRbeF14_1efYKt1OdgiEuG_
总结: 作者|GaryMarcus译者|Sambodhi策划|Tina导读：深度学习领域正步入一个激动人心的转折点，众多早期的预测与期待即将面临现实的检验。人工智能是否能在此刻实现真正的飞跃，成为各界关注的焦点。本文将深入剖析深度学习所遭遇的种种挑战，并展望其未来的发展趋势。通过回顾作者两年前的前瞻性文章，我们可以发现其中的许多观点至今仍然掷地有声。然而，随着技术的日新月异与思想的不断演进，我们亦需审视当前的形势，寻找突破困境的新路径。人工智能的发展不仅依赖于计算机科学的进步，更需要伦理学、社会学等多领域知识的融合与支持，同时离不开全球范围内的深入合作。本文将引领读者共同探讨这些问题，探寻人工智能未来的发展方向，以期在这个关键时刻为行业提供有价值的洞见与启示。两年前，我发表了一篇颇具争议的文章，标题为《深度学习正遭遇瓶颈》（DeepLearningisHittingaWall）。这篇文章虽未引起广泛关注，但却在特定群体中引发了激烈的讨论。当时，我的观点引起了众多异议，一些人甚至在Twitter上对我展开了尖锐的嘲讽。比如，SamAltman就在Dall-E诞生后不久，对我的观点进行了戏谑式的嘲讽。然而，随着时间的推移，我们有必要重新审视这篇文章的观点，看看它是否经受住了时间的考验。从技术进步的角度来看，无疑取得了显著的成就。GPT-4、Sora、Claude-3等模型的出现，以及消费者对人工智能技术的快速接受，都证明了深度学习领域的蓬勃发展。然而，这些成就并非文章所关注的重点。我的文章主要探讨了通用智能所面临的障碍，以及为何仅仅通过扩大模型规模无法解决根本问题。现在，让我们按照文章的结构，逐一审视我当时的观点。在2016年，Hinton曾预测深度学习将取代放射科医生。我写道“快进到2022年，我们观察到的事实是，没有任何一个放射科医生被深度学习技术所取代。”这一观点至今仍然成立。“目前至少是这样，人类和机器互补彼此的优势。”这一观点至今仍然成立。“很少有领域像人工智能一样充斥着炒作和虚张声势。十年来，这一行业一直在不同的时间点内跃跃欲试，不断给出令人振奋的承诺，但真正实现突破的案例却并不多见。”这一观点至今仍然成立。在2020年11月，Hinton曾向《麻省理工科技评论》（MITTechnologyReview）表示，深度学习将能够做任何事情。对于这一观点，我持怀疑态度。到目前为止，我的怀疑态度仍然如此，可以说这一观点仍然存在争议。“我们距离真正能够理解人类语言的机器，确实还有相当漫长的道路需要探索。”这一观点至今仍然成立，尽管有人认为存在一些表面上的理解。“我们目前所拥有的人工智能技术，与科幻作品中描绘的如Rosey机器人那样的日常智能水平相比，仍然相去甚远。Rosey作为一个科幻管家，不仅能够解读并解释多种多样的人类请求，更能实时、安全地执行这些请求。”这一观点至今仍然成立。至于ElonMusk关于新型人形机器人“Optimus”的设想，虽然其愿景宏大，但我对此同样持怀疑态度。要实现大规模商业化，并在短期内超越汽车工业这样的成熟产业，显然是不现实的。现在还为时过早，但可以确定的是，短期内这一领域不太可能成为任何人的大生意。“谷歌推出的最新语言模型Lambda，确实如之前所述，其稳定性受到质疑。其作者也坦诚承认，该模型在某些情况下容易产生无意义的‘废话’。”这一观点至今仍然成立。“对于深度学习在构建可信赖人工智能中的角色，我认为它仅仅是我们所需技术的一小部分。”这一猜测仍然未定，但请注意，像RAG这样的技术导入了我所倡导的符号技术。我们离可信赖的人工智能还有很长的路要走。“深度学习本质上是一种识别模式的技术，它在某些场景下表现出色，尤其是当我们只需要粗略结果、风险较低且完美结果不是必需的时候。”这一观点至今仍然成立。“目前的深度学习系统经常犯下一些看似愚蠢的错误。”这一观点至今仍然成立。“关于GPT-3等语言模型在特定应用中的潜在风险，特别是作为自动自杀辅导聊天机器人的担忧，确实有其合理性。这类系统如果未能精心构建防护措施，很容易产生问题性的对话，甚至可能误导用户。”考虑到已经发生过与聊天机器人相关的死亡事件，这种担忧并非空穴来风。“GPT-3等模型确实存在产生有害语言和传播错误信息的风险。”这一观点至今仍然成立，尽管在一些方面有所进展。（即使在某些情况下，通过技术手段限制了其产生有害语言的倾向，但在普通使用中，错误信息仍然很普遍。）“OpenAI的新努力在解决这些问题上可能仍然会制造‘权威的胡言乱语’”这一观点仍然成立。“2020年，OpenAI的JaredKaplan及其合作者提出了一组关于语言神经网络模型的‘规模定律’（scalinglaw）：他们发现，他们向神经网络输入的数据越多，这些网络的性能就越好。这暗示着，如果我们收集更多数据并将深度学习应用于越来越大的规模，我们就能够做出更好的人工智能。”规模无疑已经有所帮助，但并没有解决我上面指出的任何问题。“对于规模论点中的漏洞，确实存在对真正理解的迫切需求。目前所扩展的措施，如预测句子中的单词，虽然在一定程度上反映了模型的性能，但并不能等同于真正的人工智能所需的深度理解。”这一观点至今仍然成立，并且越来越被认可。“规模定律并不是像万有引力那样的普适‘定律’，它更像是一个基于观察得出的趋势。与摩尔定律类似，它可能在一定时期内有效，但并不能保证永远成立。”这一观点至今仍然成立，而且最近SamAltman的公开言论也表明了这一点，他承认在真正了解GPT-5等更大规模模型的能力之前，我们还有很多未知需要探索。SamAltman在一篇充满胜利感的博客文章中宣扬“万物的摩尔定律”，声称我们只需几年的时间就能实现“能够思考的计算机”，可以阅读法律文件并提供医疗建议。然而过去两年来，我们还没有看到可靠的版本能够完全实现这些功能，因此这一观点仍然有待观察。“如果规模不能让我们实现安全的自动驾驶，那么数百亿美元的投资可能会白费。”事实证明，尽管数百亿美元已经投入到了这个领域，但商业化推出仍然面临诸多难题，测试也仍然受到限制。多家公司在这个领域遭遇失败或选择放弃。因此，这一观点同样有待观察。“神经符号学可能是一个有希望的替代方案。”这一观点有待观察，而且，DeepMind刚刚在《自然》（Nature）杂志上发表了一篇关于神经符号系统AlphaGeometry的精彩论文。规模可能无法解决人工智能面临的所有问题，这一隐含的意思在当前的讨论中逐渐凸显出来。像BillGates、DemisHassabis、YanLeCun和SamAltman都意识到，可能即将出现一个平台。这一观点有待观察。上个月，Hassabis就回应了我在2022年文章中的中心观点：这并不意味着我们无法在未来见证新的技术革新，无论它们以何种形式呈现。同样，断言AGI（通用人工智能）的不可能性也过于绝对。然而，我坚信我们仍然需要一场范式转变。随着技术的深入发展，我们越来越认识到，仅仅依赖大型语言模型（LLM）可能并非通往AGI的终极答案——这一观点正是我之前所坚持的。综上所述，我认为这篇文章的观点犀利且切中要害。时光荏苒，两年间虽然技术进步日新月异，但我的核心观点仍然坚定。我可能会更新一些实例，并对标题进行微调，以更清晰地传达我的意图：即在某些领域取得的进步，并不等同于在所有方向上都有突破。我仍会毫不犹豫地表达我的担忧。最后，我想重申文章末尾的观点，这依然是无可辩驳的事实。伦理和计算方面的挑战层出不穷，我们需要汲取语言学、心理学、人类学和神经科学等多领域的智慧，而不仅仅是局限于数学和计算机科学。要培育出真正的人工智能，需要集结全社会的力量与智慧。我们必须铭记，人脑作为已知宇宙中最复杂的系统之一，若我们要构建与其相媲美的智能体系，开放与合作的精神将是我们取得成功的关键。作者简介：GaryMarcus，科学家，《Rebooting.AI》（《福布斯》AI七本必读书籍之一）、《Kluge》和《GuitarZero》作者；GeometricIntelligence创始人兼首席执行官（已被Uber收购）。原文链接https://garymarcus.substack.com/p/two-years-later-deep-learning-is零一万物刷榜，Zilliz呛声：面向投资人编程；李彦宏称“程序员将会消失”，周鸿祎回怼；TikTok危在旦夕|Q资讯敲了17年代码，我现在连个面试机会都得不到“微软已经沦落为OpenAI的一个IT部门”！资源倾斜引发微软内部员工不满、高管离职90后华人团队真来砸程序员饭碗了！推出全球首个AI超级工程师：拥有全栈技能，一个指令就能完成整个开发过程返回搜狐，查看更多责任编辑：平台声明：该文观点仅代表作者本人，搜狐号系信息发布平台，搜狐仅提供信息存储空间服务。&nbsp;首赞+1点赞失败阅读(651)内容举报
关键词: 深度学习, 通用智能, 规模定律, 伦理和计算
AI技术: GPT-4, Sora, Claude-3, Lambda, AlphaGeometry
行业: 放射科, 计算机科学语言学
重大事件摘要: 这篇文章是作者GaryMarcus对深度学习领域的回顾与展望。两年前，他发表了一篇颇具争议的文章《深度学习正遭遇瓶颈》，引发了广泛的讨论和争议。在这篇文章中，他对深度学习的发展提出了一些质疑和担忧，认为深度学习在实现通用智能方面面临着许多挑战。

两年过去了，作者回顾了自己的观点，并发现其中许多观点仍然成立。他认为，尽管深度学习领域取得了显著的成就，如GPT-4、Sora、Claude-3等模型的出现，但这些成就并不能解决通用智能所面临的根本问题。他还指出，深度学习系统经常犯下一些看似愚蠢的错误，存在产生有害语言和传播错误信息的风险。

此外，作者还提到了OpenAI的JaredKaplan及其合作者提出的关于语言神经网络模型的“规模定律”，并对此表示怀疑。他认为，规模虽然有所帮助，但并没有解决他所指出的问题。最后，作者强调了伦理和计算方面的挑战，以及需要汲取多领域的智慧来培育真正的人工智能。

总的来说，这篇文章总结了作者对深度学习领域的回顾与展望，提出了一些质疑和担忧，并对未来的发展方向进行了探讨。
