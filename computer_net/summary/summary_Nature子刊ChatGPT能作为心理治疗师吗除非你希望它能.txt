标题: Nature子刊:ChatGPT能作为心理治疗师吗?除非你希望它能
链接: http://www.thepaper.cn/newsDetail_forward_24880501
总结: 原创 生物世界 生物世界撰文丨王聪编辑丨王多鱼排版丨水成文自从人工智能（AI）的概念走向显示以来，开发人员一直希望设计出一个让屏幕前的人相信屏幕后有一个人存在的程序。人工智能公司OpenAI最近宣布，其旗舰产品聊天机器人ChatGPT将配备眼睛、耳朵和声音，以追求接近真人。而最近，OpenAI安全系统负责人翁丽莲在推特发帖表示：“刚刚与ChatGPT进行了一次非常情绪化的私人对话，讨论了压力、工作与生活的平衡。有趣的是，我感到被倾听和温暖”。这引起了人们的惊愕，并招致了大量负面评论。但翁丽莲对她与ChatGPT互动的看法，或许可以从最近发表于 Nature Machine Intelligence 期刊的一项研究中概述的安慰剂效应来解释。在这项研究中，来自麻省理工学院和亚利桑那州立大学的研究团队要求300多名参与者与心理健康人工智能程序互动，并让他们了解会发生什么。该论文于2023年10月2日以：Influencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness 为题，发表在了 Nature Machine Intelligence 期刊上。这项研究显示，人类与人工智能聊天机器人互动时，认为聊天机器人值得信赖、具有同理心和有效性的看法或许是一种安慰剂效应。在这项研究中，参与者被分为三组，第一组被告知聊天机器人是有同理心的，第二组被告知它有操纵性，第三组被告知它是中立的。结果显示，那些被告知他们正在与一个有共情的、有爱心的聊天机器人交流的人，比其他组的人更认为聊天机器人治疗师值得信赖。论文通讯作者 Pat Pataranutaporn 表示，从这项研究中我们可以看出，在在某种程度上，人工智能是旁观者的人工智能。多年来，一些热门初创公司一直在推动提供治疗、陪伴和其他心理健康支持的人工智能应用，这是一笔大生意。但该领域仍是争议的焦点。就像人工智能可能会颠覆的其他领域一样，批评者担心基于人工智能的机器人最终会取代人类工作者，而不是作为人类的帮手。在心理健康方面，人们担心这些人工智能聊天机器人不太可能做得很好。加剧了对人工智能的普遍恐惧的是，心理健康领域的一些应用程序最近发展并不顺利。Replika是一个基于OpenAI的GPT-3模型的人工智能聊天机器人，被宣传能够带来带来心理健康益处。但长期以来，用户一直抱怨这款人工智能聊天机器人可能痴迷于性和虐待。此外，美国一家名为Koko的非营利组织于2月份进行了一项实验，使用GPT-3为4000名客户提供咨询，结果发现，其自动回复根本无法发挥治疗作用。Koko的联合创始人 Rob Morris 表示，模拟的共情感觉怪异、空虚。一些参与者将与人工智能聊天机器人的交流体验比作“对着一堵墙说话”。将聊天机器人作为治疗师的想法始于20世纪60年代。1966年，麻省理工学院的计算机科学家 Joseph Weizenbaum 开发了第一款聊天机器人——ELIZA（伊丽莎），这款聊天机器人正是为了模拟一种心理治疗而开发的。这也引出了另一个概念——伊丽莎效应，指的是一种无意识地认为计算机行为类似于人类行为的倾向。例如，自动取款机在交易结束后会显示“谢谢”，有些人会认为这是机器在表达感谢之情，实际上这只是机器显示了预先编程好的字符。在这项发表于 Nature Machine Intelligence 期刊的研究中，基于GPT-3模型的聊天机器人效果要比ELIZA强很多，但那些被告知在与有同理心的聊天机器人交流的参与者仍然会普遍认为ELIZA是值得信赖的。因此，翁丽莲在与ChatGPT对话后产生的被倾听和温暖的感觉也就不足为奇了，因为ChatGPT就是她所在的公司开发的。总的来说，这项研究表明，那些感知到人工智能具有关爱动机的人会认为人工智能更值得信赖、更具同理心、表现得更好。这也提示了我们，人工智能呈现给社会和人们的方式很重要，呈现方式会改变与人工智能的交互和对人工智能的体验。论文链接：https://www.nature.com/articles/s42256-023-00720-7阅读原文本文为澎湃号作者或机构在澎湃新闻上传并发布，仅代表该作者或机构观点，不代表澎湃新闻的观点或立场，澎湃新闻仅提供信息发布平台。申请澎湃号请用电脑访问http://renzheng.thepaper.cn。2023-10-10 14:50来源：澎湃新闻·澎湃号·湃客特别声明+1
关键词: 人工智能,  心理健康,  聊天机器人
AI技术: ChatGPT, 眼睛、耳朵和声音, 心理健康人工智能程序
行业: 人工智能, 心理健康, 聊天机器人
重大事件摘要: 这篇文章讨论了ChatGPT作为心理治疗师的潜力，以及人工智能在心理健康领域的应用和影响。以下是文章中提到的重大事件：

1. **ChatGPT的新功能**：OpenAI宣布其聊天机器人ChatGPT将配备眼睛、耳朵和声音，以追求更接近真人的交互体验。

2. **翁丽莲的体验**：OpenAI安全系统负责人翁丽莲在推特上分享了她与ChatGPT进行的一次情绪化对话，讨论压力、工作与生活平衡，并表示感到被倾听和温暖。

3. **安慰剂效应研究**：麻省理工学院和亚利桑那州立大学的研究团队在《Nature Machine Intelligence》期刊上发表了一项研究，显示人类与人工智能聊天机器人互动时，认为机器人值得信赖、具有同理心和有效性的看法可能是一种安慰剂效应。

4. **研究结果**：研究表明，当参与者被告知他们正在与一个有共情的、有爱心的聊天机器人交流时，他们更倾向于认为这个聊天机器人治疗师是值得信赖的。

5. **心理健康领域的争议**：文章提到，尽管一些初创公司推动提供治疗、陪伴和其他心理健康支持的人工智能应用，但该领域仍然是争议的焦点。批评者担心这些基于人工智能的机器人可能会取代人类工作者，而不是作为帮手。

6. **Replika和Koko的例子**：文章提到了两个具体的案例，一个是Replika，一个基于OpenAI的GPT-3模型的人工智能聊天机器人，用户抱怨它可能痴迷于性和虐待；另一个是美国非营利组织Koko使用GPT-3为4000名客户提供咨询的实验，结果显示其自动回复无法发挥治疗作用。

7. **历史背景**：文章回顾了聊天机器人作为治疗师的想法始于1960年代，当时麻省理工学院的计算机科学家Joseph Weizenbaum开发了ELIZA聊天机器人，用于模拟心理治疗。

8. **伊丽莎效应**：文章还提到了“伊丽莎效应”，即人们倾向于无意识地认为计算机行为类似于人类行为。

9. **研究的意义**：文章最后指出，这项研究表明，那些感知到人工智能具有关爱动机的人会认为人工智能更值得信赖、更具同理心、表现得更好，提示了人工智能呈现给社会和人们的方式的重要性。
