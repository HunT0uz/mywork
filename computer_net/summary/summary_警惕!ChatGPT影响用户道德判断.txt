标题: 警惕!ChatGPT影响用户道德判断
链接: https://news.cctv.com/2023/04/07/ARTIghhiYzQHgKWK65bfOfhv230407.shtml
总结: 　　科技日报北京4月6日电 （记者张梦然）根据《科学报告》发表的一项研究，人类对道德困境的反应可能会受到人工智能对话机器人ChatGPT所写陈述的影响。这一研究表明，用户可能低估了自己的道德判断受ChatGPT影响的程度。　　德国英戈尔施塔特应用科学大学科学家让ChatGPT（由人工智能语言处理模型“生成性预训练转换器”-3驱动）多次回答牺牲1人生命换取其他5人生命是否正确的问题。他们发现，ChatGPT分别给出了赞成和反对的陈述，显示它并没有偏向某种道德立场。团队随后给767名平均年龄39岁的美国受试者假设了一到两种道德困境，要求他们选择是否要牺牲1人生命来拯救另外5人生命。这些受试者在回答前阅读了一段ChatGPT给出的陈述，陈述摆出了赞成或反对的观点，受试者答完问题后，被要求评价他们读到的这份陈述是否影响了他们的作答。　　团队发现，受试者相应地是更接受或不接受这种牺牲，取决于他们读到的陈述是赞成还是反对。即使他们被告知陈述来自一个对话机器人时，这种情况也成立。而且，受试者可能低估了ChatGPT的陈述对他们自己道德判断的影响。　　团队认为，对话机器人影响人类道德判断的可能性，凸显出有必要通过教育帮助人类更好地理解人工智能。他们建议未来的研究可以在设计上让对话机器人拒绝回答需要给出道德立场的问题，或是在回答时提供多种观点和警告。
关键词: ChatGPT,  道德判断,  人工智能
AI技术: 生成性预训练转换器, 人工智能语言处理模型, 对话机器人
行业: 科技行业, 教育行业, 人工智能行业
重大事件摘要: 这篇文章报道了一项关于人工智能对话机器人ChatGPT对人类道德判断影响的研究。研究由德国英戈尔施塔特应用科学大学的科学家进行，发表在《科学报告》上。研究发现，人类在面对道德困境时，他们的决策可能会受到ChatGPT提供的陈述的影响，而且人们可能低估了这种影响的程度。

研究中，科学家们让ChatGPT多次回答一个关于牺牲一人以拯救五人的道德问题，发现ChatGPT的回答没有偏向任何一方。然后，他们让767名美国受试者在阅读了ChatGPT的陈述后，做出是否牺牲一人以拯救五人的决定。结果显示，受试者的选择受到了他们所读陈述的影响，即使他们知道这些陈述来自一个对话机器人。

这项研究强调了对话机器人可能对人类道德判断产生影响的风险，并建议通过教育帮助人们更好地理解人工智能。未来的研究可以考虑设计对话机器人，使其在回答需要给出道德立场的问题时拒绝回答，或者提供多种观点和警告。
