标题: 什么是机器学习算法? | IBM
链接: http://www.baidu.com/link?url=-KmgkV2XGanNA17f-rn88TrxGyz83aD-C-ygxWZeyCyGtimuoDY7GESlpAs1PcV1Wn3yY6H8k6UYBSaX_pFgs4P3ONZP--r6HfANnBAgKGu
总结: 监督学习算法在进行数据挖掘时，监督学习可以分为两类问题：分类和回归。分类使用算法将测试数据准确分配到特定类别。它可识别数据集中的特定实体，并尝试就如何标记或定义这些实体得出一些结论。常见的分类算法有线性分类器、支持向量机(SVM)、决策树、K最邻近和随机森林，下面将做详细介绍。回归&nbsp;用于理解因变量和自变量之间的关系。回归通常用于进行预测，例如给定业务的销售收入。线性回归、逻辑回归和多项式回归是常用的回归算法。监督机器学习过程中使用了各种算法和计算技术，通常通过使用Python等程序进行计算。监督学习算法包括：AdaBoost或梯度提升：也称为自适应提升7，该技术将某个表现欠佳的回归算法与一些更弱的回归算法相结合，从而让该算法得以增强，并最终减少了错误。提升组合运用了多个基础估算器的预测能力。人工神经网络：也称为ANN、神经网络或模拟神经网络(SNN)，是机器学习技术的子集，同时也是深度学习算法的核心。学习器算法使用称为神经元的构建块来识别输入数据中的模式，此类神经元近似于人脑中的神经元，会随着时间的推移进行训练和修改。（详细内容请见“神经网络”。）决策树算法：用于预测数值（回归问题）以及将数据分类，决策树采用可通过树形图表示的关联决策的分支序列。决策树的优势之一是易于验证和审计，这一点与神经网络的黑匣不同。降维：如果选定的数据集具有大量特征7，那么它的维度也较高。降维会减少特征数，仅留下最有意义的见解或信息。其中一个例子是主成分分析。K最邻近：也称为KNN，这种非参数算法根据数据点与其他可用数据的接近度和关联度对数据点进行分类。此算法假定可以在各数据点附近找到相似的数据点。因此，此算法试图计算数据点之间的距离（通常通过欧几里德距离计算），然后根据最常见的类别或平均值来指定类别。线性回归：线性回归用于识别因变量与一个或多个自变量之间的关系，通常用于预测未来结果。当只有一个自变量和一个因变量时，称为简单线性回归。逻辑回归：当因变量为连续变量时，采用线性回归；当因变量为分类变量时，即存在二元输出，例如“真”和“假”或“是”和“否”，采用逻辑回归。虽然这两种回归模型都试图理解数据输入之间的关系，但逻辑回归主要用于解决二元分类问题，例如垃圾邮件识别。神经网络：主要用于深度学习算法，神经网络通过节点层来模仿人脑的互连，进而处理输入训练数据。每个节点由输入、权重、偏差（阈值）和输出组成。如果该输出值超过给定阈值，将“触发”或激活节点，并将数据传递到网络中的下一层。神经网络通过梯度下降过程从基于损失函数的调整中学习。当成本函数为零或接近零时，您可以确信该模型准确可靠。朴素贝叶斯：这种方法采用类条件独立原则，该原则来自贝叶斯定理。这意味着在给定结果的概率中，一个特征的存在不会影响另一个特征的存在，并且每个预测变量对该结果具有相同的影响。朴素贝叶斯分类器分为三种类型：多项式朴素贝叶斯、伯努利朴素贝叶斯和高斯朴素贝叶斯。这种技术主要用于文本分类、垃圾邮件识别和推荐系统。随机森林：在随机森林中，机器学习算法通过组合来自多个决策树的结果来预测一个值或一个类别。“森林”是指不相关的决策树，它们聚集起来以减少方差并提升预测的准确度。支持向量机(SVM)：此算法可用于数据分类和回归，但通常用于分类问题，构建一个两类数据点之间距离最大的超平面。这个超平面称为决策边界，将平面两侧的数据点类别（例如橙子与苹果）分开。
关键词: 监督学习, 分类, 回归, 决策树
AI技术: 机器学习算法, 监督学习, 回归, 分类, 决策树
行业: 数据挖掘,  预测分析,  文本分类
重大事件摘要: 这篇文章详细介绍了机器学习中的监督学习算法，包括分类和回归两大类问题。文章首先解释了分类和回归的基本概念，然后列举并详细描述了多种常用的监督学习算法，如线性分类器、支持向量机(SVM)、决策树、K最邻近、随机森林等。此外，文章还介绍了一些特定的算法和技术，如AdaBoost或梯度提升、人工神经网络、朴素贝叶斯、逻辑回归和多项式回归等。这些算法和技术在机器学习中有着广泛的应用，可以帮助我们从数据中学习和提取有用的信息。
