标题: 被指作假、诽谤,ChatGPT可能“吃官司”?
链接: https://baijiahao.baidu.com/s?id=1762880469673314176&wfr=spider&for=pc
总结: 中新网4月11日电(甘甜)被指杜撰新闻报道、对他人提出诽谤指控，编造虚假期刊文章……风头正劲的人工智能软件ChatGPT，给人们带来便利的同时，也造成了一些麻烦。像ChatGPT这样的人工智能软件，究竟将对人类未来产生怎样的影响？担忧之下，多个国家和机构接连采取措施，加强对ChatGPT的监管。图片来源：ChatGPT资料图。造假诽谤？造假诽谤？ChatGPT或惹上官司ChatGPT或惹上官司具备语言理解、生成、知识推理能力的ChatGPT，由美国人工智能研究实验室OpenAI在2022年11月30日推出。推出两个月，即拥有1亿活跃用户，并带动了人工智能的新热潮。然而，知名度越来越高的同时，ChatGPT却惹上了不小的麻烦。澳大利亚赫本郡郡长胡德表示，如果OpenAI公司不改正ChatGPT关于“他曾因行贿入狱”的虚假说法，他可能将诉诸法律。图片来源：路透社报道截图澳大利亚赫本郡郡长胡德(Brian Hood)表示，他可能会对OpenAI公司提起诉讼——他被ChatGPT误列为澳大利亚储备银行子公司一桩外国贿赂丑闻的“犯案者”。胡德表示，如果开发公司OpenAI不改正ChatGPT关于“他曾因行贿入狱”的虚假说法，他可能将诉诸法律。路透社指出，澳大利亚的诽谤赔偿金通常上限为 40万澳元。律师说，胡德尚不清楚获得有关他的虚假信息的确切人数，而这是赔付金额的决定因素。诽谤性言论的性质往往非常严重，胡德可能会索赔超过20万澳元。无独有偶，美国法学教授特利(Jonathan Turley)也遇到了类似的情况。图片来源：《今日美国》报道截图特利4月3日在《今日美国》发文称，自己收到了一封邮件，被告知有人在测试ChatGPT时发现，他出现在了ChatGPT给出的性骚扰学生的名单中。ChatGPT的答案声称援引了《华盛顿邮报》的报道——“乔治城大学法律中心教授特利2018年3月被一名女学生指控性骚扰，事件发生在阿拉斯加。”但事实并非如此。特利称，他从来没有去过阿拉斯加，《华盛顿邮报》也根本没有写过这篇报道。此外，特利发现，ChatGPT同时列出的其他四个性骚扰案例中，还有两个案例似乎也是假的。此外，几天前，英国《卫报》编辑莫兰(Chris Moran)发文称，“ChatGPT正在编造虚假的《卫报》文章”。莫兰透露，上月，该媒体收到了一封邮件，一名研究人员提到了《卫报》的一篇文章，指这篇文章是一名记者在数年前针对特定主题所写，但在网上怎么也找不到原文。后经《卫报》证实，并没有人写过该篇文章，相关内容很可能是由ChatGPT杜撰。对于ChatGPT虚假信息的风险，不少医生也发出了警告，呼吁不要使用ChatGPT获取健康资讯。有研究指出，ChatGPT援引的医学资料来源过于单一，加上AI不能进行临床判断，也无须担负医护道德责任，患病后依赖ChatGPT问诊存在风险。美国马里兰大学医学院的研究人员还称，ChatGPT有时会编造虚假的期刊文章，或伪造健康机构来支持其说法，“用户应该依靠医生而非ChatGPT来寻求建议。”建立网络建立网络人工“大脑”这样运作人工“大脑”这样运作那么，ChatGPT究竟是如何运作的？据《纽约时报》介绍，ChatGPT的工作原理是大型语言模型(LLM)，是AI领域相对较新的训练模型，约在5年前首次出现，如今已可以起草电子邮件、演示文稿和备忘录等。资料图：OpenAI公司的标识。第一步：设定目标AI系统须预先设定目标函数，大多数LLM模型的基本目标函数为：给定一个文本序列，猜测接下来的内容。第二步：收集大量数据大量收集训练数据。理想情况下，通常从互联网上搜集数十亿个页面作为数据库，如博客文章、推文、维基百科和新闻报道等。第三步：建立神经网络接下来，组装人工智能的“大脑”：即AI的神经网络系统。这是一个由相互连接的节点(或“神经元”)组成的复杂网络，用于处理和存储信息。第四步：训练神经网络通过训练，AI模型学会分析数据，识别不同模式和关系，学会如何构建有意义的信息。相关训练耗时几天甚至几周，耗费巨大的计算能力。第五步：微调模型一个大型语言模型被训练出来，需要为特定的工作或领域进行校准，通常由人类进行微调。第六步：上线启动经过训练和微调后，就可以开始使用。谨慎使用谨慎使用多国收紧对ChatGPT监管多国收紧对ChatGPT监管“人工智能系统可能并不稳定且不可预测，甚至造成危险。”《纽约时报》提醒称，人们使用ChatGPT时，仍需要多多当心。为此，近段时间以来，多国也收紧了对ChatGPT的监管。·3月31日，意大利个人数据保护局宣布，暂时禁止使用ChatGPT，限制OpenAI公司处理意大利用户信息，并开始立案调查。德国据称也在考虑是否效仿意大利。·美欧多所大学已禁止学生使用ChatGPT，纽约市教育局禁止当地的公立学校电脑以及网络使用ChatGPT。·美国部分律所、摩根大通银行等已限制使用ChatGPT。·韩国三星电子员工疑似因使用ChatGPT，泄露公司机密。为杜绝类似事故再发生，三星要求员工注意ChatGPT的使用方式，并正在制定相关保护措施。（来源：中国新闻网）举报/反馈
关键词: ChatGPT, 诽谤指控, 监管收紧
AI技术: ChatGPT, 大型语言模型(LLM), 神经网络系统
行业: 人工智能, 新闻传媒, 法律
重大事件摘要: 这篇文章报道了人工智能软件ChatGPT面临的一系列问题和挑战，包括被指控制造虚假信息、诽谤个人以及编造不实内容。以下是文章中提到的重大事件：

1. **ChatGPT的迅速崛起**：自2022年11月30日由OpenAI推出以来，ChatGPT在短短两个月内吸引了1亿活跃用户，成为人工智能领域的一个热点。

2. **澳大利亚赫本郡郡长Brian Hood的法律威胁**：Hood表示，如果OpenAI不更正ChatGPT关于他因行贿入狱的错误说法，他可能会对OpenAI提起诉讼。这起事件凸显了ChatGPT可能产生的法律风险。

3. **美国法学教授Jonathan Turley的遭遇**：Turley被错误地列为性骚扰学生的人之一，尽管他从未去过阿拉斯加，也没有相关的《华盛顿邮报》报道。这一事件进一步暴露了ChatGPT生成虚假信息的问题。

4. **英国《卫报》编辑Chris Moran的揭露**：Moran指出，有人声称《卫报》发表了一篇不存在的文章，而这篇文章很可能是由ChatGPT编造的。

5. **医疗健康信息的警告**：医生和研究人员警告不要依赖ChatGPT获取健康信息，因为其医学资料来源单一且无法进行临床判断。

6. **多国加强对ChatGPT的监管**：由于担心ChatGPT的稳定性和预测性，多个国家和机构开始收紧对其的监管。例如，意大利暂时禁止使用ChatGPT，并开始调查；德国也在考虑类似措施。此外，一些大学和公司也限制或禁止使用ChatGPT。

7. **三星电子的信息泄露事件**：据报道，三星电子的员工可能因使用ChatGPT而泄露了公司机密，这导致三星要求员工注意ChatGPT的使用方式，并正在制定相关保护措施。

这些事件表明，尽管ChatGPT等人工智能技术带来了便利和创新，但同时也伴随着隐私、安全和法律责任等方面的重大挑战。
