标题: 视觉版ChatGPT来了!吸收AI画画全技能,MSRA全华人团队打造
链接: https://baijiahao.baidu.com/s?id=1759956051617253786&wfr=spider&for=pc
总结: 明敏 发自 凹非寺量子位 | 公众号 QbitAI明敏 发自 凹非寺量子位 | 公众号 QbitAIChatGPT会画画了！问它：能生成一张猫片给我吗？立刻连文带图全有了。还能根据新的文字指令调整图片：把猫换成狗。同时也看得懂图、有理解能力。比如发一张图给它，然后问摩托是什么颜色？它能回答出是黑色。如上，就是由MSRA资深研究人员们提出的视觉版ChatGPT（Visual ChatGPT）。视觉版ChatGPT通过给ChatGPT结合多种视觉模型，并利用一个提示管理器（Prompt Manager），他们成功让ChatGPT可以处理各种视觉任务。这项工作一发出来就火了，GitHub揽星已超过1.5k。简单总结一下，就是把GPT和Dall-E合并的感觉~又懂文字又会画图……有人就说：这不是终极meme图制造机？这不是终极meme图制造机？诀窍在于提示工程？Visual ChatGPT，其实就是让ChatGPT可以处理多模态信息。但是从头训练一个多模态模型，工作量非常大。研究人员想到可以在ChatGPT的基础上，结合一些视觉模型。结合一些视觉模型而想要达到这一目的，关键需要一个中间站。由此他们提出了提示管理器（Prompt Manager）的概念。提示管理器它的作用主要有3方面：第一、明确告诉ChatGPT，每个视觉模型的作用，并指定好输入输出格式。第一第二、转换不同的视觉信息，如将PNG图像、深度图像、掩码矩阵等转换为语言格式，方便ChatGPT理解。第二第三、处理视觉模型的历史生成结果，以及不同模型的调用优先级、规避冲突等，让ChatGPT能够以迭代的方式接收视觉模型的生成内容，直到输出用户满意的结果。第三迭代这样一来，Visual ChatGPT的工作流大概长这样：假如用户输入了一张图，模型会先将内容发送给提示管理器，然后转换成语言给ChatGPT判断，当它发现这个问题不需要调用视觉模型，就会直接给出输出（第一个回答）。第二个问题时，ChatGPT分析问题内容需要使用视觉模型，就会让视觉模型开始执行，然后一直迭代，直到ChatGPT判断不再需要调用视觉模型时，才会输出结果。论文介绍，Visual ChatGPT中包含了22个不同的视觉模型。包括Stable Diffusion、BLIP、pix2pix等。为了验证Visual ChatGPT的能力，他们还进行了大量零次试验（zero-shot experiments）。结果如开头所示，Visual ChatGPT具备很强的图像理解能力。可以一直按照人的需求不断生成、修改图片。当然，研究人员也提到了这项工作目前还存在一些局限性。局限性比如生成结果的质量，主要取决于视觉模型的性能。以及使用大量的提示工程，会一定程度上影响生成结果的速度。而且还可能同时调用多个模型，也会影响实时性。最后，在输入图片的隐私安全上，还需要做进一步升级保护。MSRA老将出马本项研究成果来自微软亚洲研究院的团队。微软亚洲研究院通讯作者是段楠。段楠他是MSRA首席研究员，自然语言计算组研究经理，中国科学技术大学兼职博导，天津大学兼职教授，CCF杰出会员。主要从事自然语言处理、代码智能、多模态智能、机器推理等研究。2012年加入MSRA，任职已超10年。第一作者为吴晨飞。他于2020年加入微软，目前担任高级研究员。论文地址：https://arxiv.org/abs/2303.04671参考链接：https://twitter.com/_akhaliq/status/1633642479869198337举报/反馈
关键词: 视觉版ChatGPT, MSRA提示管理器
AI技术: ChatGPT, 视觉模型, 提示管理器
行业: 人工智能, 计算机视觉, 自然语言处理
重大事件摘要: 这篇文章主要介绍了微软亚洲研究院(MSRA)团队开发的一种名为视觉版ChatGPT的新技术。这项技术通过将ChatGPT与多种视觉模型结合，并利用一个提示管理器（Prompt Manager），使得ChatGPT能够处理各种视觉任务，如生成和修改图片、理解图片内容等。

以下是文章的重大事件总结：

1. **视觉版ChatGPT的开发**：由MSRA全华人团队打造，结合了ChatGPT和多种视觉模型，使其能够处理多模态信息。
   
2. **提示管理器的作用**：提示管理器在视觉版ChatGPT中起到了关键作用，它负责明确每个视觉模型的作用，转换视觉信息为语言格式，并处理视觉模型的历史生成结果，协调不同模型的调用优先级。

3. **工作流程**：用户输入图像后，提示管理器将其转换为语言信息给ChatGPT判断。如果需要调用视觉模型，模型会迭代执行，直到ChatGPT判断不再需要调用视觉模型时输出结果。

4. **包含的视觉模型**：视觉版ChatGPT中包含了22个不同的视觉模型，包括Stable Diffusion、BLIP、pix2pix等。

5. **零次试验验证能力**：为了验证Visual ChatGPT的能力，研究人员进行了大量的零次试验，结果表明其具备很强的图像理解能力，可以按照人的需求不断生成和修改图片。

6. **局限性**：尽管功能强大，但Visual ChatGPT目前还存在一些局限性，如生成结果的质量取决于视觉模型的性能，大量的提示工程会影响生成速度，多个模型的调用可能会影响实时性，以及输入图片的隐私安全问题。

7. **研究团队**：研究成果来自微软亚洲研究院的团队，通讯作者是段楠，他是MSRA首席研究员，自然语言计算组研究经理。第一作者为吴晨飞，他于2020年加入微软，目前担任高级研究员。
