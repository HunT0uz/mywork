标题: 吐血整理:机器学习的30个基本概念,都在这里了(手绘图解)|...
链接: http://www.baidu.com/link?url=ZcQ26Dh5pOoIwsCcPuy_YksSorM_fs-izZzmaBGK7fJiv8vFSbri29YTvcj1yUqF-E2Y6abcsqI32O5OEWWzGq
总结: 导读：本文主要介绍机器学习基础知识，包括名词解释（约30个）、基础模型的算法原理及具体的建模过程。作者：梅子行、毛鑫宇来源：大数据DT（ID：hzdashuju）01空间表征在学习深奥的机器学习理论之前，首先来介绍一些机器学习中最基本的概念。特征（Feature）：一个具体事物的属性描述，由属性向量表示。第j个记录xj的属性向量可以表示为：xj=(xj(1)，xj(2)，…，xj(i)，…，xj(n))，j=1，2，…，N，xj∈X其中每个xj(i)为一个特征维度上的取值。标记（Label）：又称样本标签，用于描述事物某个特性的事项。标记值：标记的取值。在二分类问题中，取值通常为0和1。标记空间（输出空间）：所有标记的集合，记为Y。样例（Sample）：又称样本。拥有了对应标记的记录，由（记录，标记）对表示。例如，第j个样例可以表示为：(xj，yj)，j=1，2，…，N，xj∈X，yj∈Y假设空间F通常是由一个参数向量决定的函数族：F={f|Y=fw(X)，w∈Rn}其中，参数向量w取值于n维向量空间Rn，称为参数空间。假设空间F也可定义为条件概率的集合（概率模型）：F={P|P(Y|X)}其中，X是定义在输入空间X上的随机变量，Y是定义在输出空间Y上的随机变量。上述公式理解起来可能较为抽象，接下来我们通过一个实际的例子来理解相关概念。首先，在建立模型前，一定会有一个由多个样例组成的样本集，比如：（用户A，{年龄：29，身高：185，年收入：70，婚姻状况：未婚，状态：逾期}）（用户B，{年龄：24，身高：167，年收入：31，婚姻状况：已婚，状态：未逾期}）（用户C，{年龄：46，身高：177，年收入：50，婚姻状况：离异，状态：未逾期}）…其中每一个用户及其属性对称为一个样本（或观测）。这样的一系列用户及其自身的属性构成了样本集，其中用户“A”“B”“C”构成了样本空间，“特征年龄”“身高”“年收入”“婚姻状况”构成了特征空间。此外还有一个空间叫作参数空间，即由组成预测函数的参数的所有取值所组成的空间。“状态”这个字段则代表着样本的标签，也就是需要模型来判别的结果。这个例子中特征空间有4个取值：年龄、身高、年收入、婚姻状况。这4个取值就代表着特征空间中的4个维度，或者说这个特征空间的维度是4。在良好的假设条件下，模型期望每个特征之间互不干扰，然而在实际情况下，通常每个特征之间都有可能存在关系。比如我们可以将其中两个维度（年龄和身高）画出来。当处于低龄时（即0～8岁），我们可以明显地观察到身高的取值随着年龄增长也在不断地变大，如图3-1所示。▲图3-1变量相关性示例婚姻状况这个特征可能取值为{未婚、已婚、离异}，那么这3个取值就限制住了特征空间在婚姻状况这个维度上的取值。如果数据中只有{未婚、离异}这2种取值的样本，则称这个数据集不能完整表征它所在的样本空间，即在它的某一特征维度上，有一些值没有被观测到，不能很好地观察到这个维度特征的真实分布。通过已观察的样本点，只能表征出阴影部分的空间，如图3-2所示。▲图3-2空间表征示例02模型学习模型的训练（又叫学习或者拟合），是指通过将数据传入模型，从而使模型学习到数据的潜在规律（如数据的分布）的过程。而建立模型的本质，可以理解为从数据分布中抽象出一个决策函数。决策函数（非概率模型）的定义为从输入空间X到输出空间Y的映射f:X→Y。假设空间F定义为决策函数的集合，其形式如下：F={f|Y=f(X)}其中，X是定义在输入空间X上的变量，X∈X；Y是定义在输出空间Y上的变量。当想要预测的是离散值时，比如一个人是男或是女，或者一个用户还钱与否，这样的任务称为分类（Classification）。与之相对应的，如果想预测一个人的年龄是多少岁，或者一个用户具体会在未来的哪一天还款，这样的任务称为回归（Regression）。当一个任务只有两个取值时称之为二分类任务。评分卡模型就是一种典型的二分类任务，即预测一个用户是否会产生逾期。而当任务涉及多个类别的时候，称之为多分类任务。一个典型的例子是在做欺诈检测时预测一个用户是否进行欺诈，这看似是一个二分类任务（预测是否欺诈），但其实用户的欺诈手段各不相同，每一个欺诈方法都是一个单独的类别，因此它本质上是一个多分类任务。从数据是否带有标签的角度来看，又可以将模型划分成三大类：监督学习（SupervisedLearning，SL）、半监督学习（Semi-SupervisedLearning，SSL）和无监督学习（UnsupervisedLearning，UL）。监督学习是指在一个申请评分卡建模中，已经明确知道样本集中每个用户的标签，即随便取一个人出来，都可以知道他的逾期状态。无监督学习是指在建模时，完全没有当前样本集的任何标签信息，即完全不知道哪些人是逾期的。而半监督学习介于两者之间，对于当前的样本集，知道其中一部分样本的标签，另一部分则不知道其是否已逾期。通常情况下，模型的效果排序如下：监督学习&gt;半监督学习&gt;无监督学习在绝大多数情况下，应该尽可能利用标签信息，这样得到的模型效果会更好。但是很多时候，是否能拥有标签并不是由个体决定的。例如，很多平台是没有欺诈用户的标签的，此时训练一个监督模型就很困难，而半监督及无监督学习可以起到一定的作用。03模型评价对于模型学习的结果，主要关心两件事：欠拟合(underfit)和过拟合(overfit)。欠拟合是指模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好地捕捉到数据特征，不能很好地拟合数据。换言之，模型在学习的过程中没有很好地掌握它该掌握的知识，模型学习的偏差较大。过拟合是指为了得到一致假设而使假设变得过度严格，即模型学习得太过详细，把一些个例的特点作为共性，使得模型的泛化能力较低。图3-3很好地解释了过拟合与欠拟合的含义，a图表示欠拟合，b图表示一个良好的拟合，c图则表示过拟合。通俗理解，过拟合就是模型学得过于细致，欠拟合就是学得过于粗糙。▲图3-3拟合优度模型结构越复杂，通常越倾向于过拟合。而样本量越大，数据分布得到越充分的曝光，模型越不容易过拟合。为了更好地表示过拟合和欠拟合，通常建模的时候会将样本集划分为训练集（Train）和测试集（Test）。训练集就是用来带入模型训练的集合，而测试集主要是待模型训练好之后，对模型做测试，以检验模型的效果。一般认为，训练集上表现好但在测试集上表现不好的模型，有过拟合的风险；而模型在训练集上效果明显差于测试集，则有欠拟合的风险。在训练一个模型的时候，我们不只希望模型在训练集上的表现足够好，还希望模型在其他数据集上的表现也很好。训练集上的表现与测试集上的表现的差值称为泛化误差，而泛化误差由3部分组成：偏差（bias）、方差（variance）、噪声（noise）。偏差度量了模型的期望预测与真实结果的偏离程度，也就是模型本身的拟合能力。方差度量了同样大小的训练集的变动所导致的学习能力的变化，也就是数据扰动所造成的影响。而噪声则刻画了问题本身的拟合难度。图3-4所示为训练程度与误差的关系。▲图3-4训练程度与误差通常离线模型训练完成后，在最终模型上线前，会将测试集和训练集整合，重新对模型的系数做拟合，进而得到最终的模型。这是因为人为数据集越大，对样本空间的表征可能越充分。某些曝光不充分的特征值所对应的标签分布，在数据量增加时，可能有更高的曝光率。比如之前例子中的数据集如下所示：（用户A，{年龄：29，身高：185，年收入：70，婚姻状况：未婚，状态：逾期}）（用户B，{年龄：24，身高：167，年收入：31，婚姻状况：已婚，状态：未逾期}）（用户C，{年龄：46，身高：177，年收入：50，婚姻状况：离异，状态：未逾期}）…如果训练集中婚姻状况有一个值没有取到，只存在于测试集中，那么将测试集和训练集合并得到最终模型时，对未来的用户进行预测时偏差就会更小。然而部分模型，如极端梯度提升机（eXtremeGradientBoosting，XGBoost）需要利用测试样本集实现训练过程的提前停止，因此需要额外选择部分样本不参与训练，比如从原始训练集中选择少部分样本作为提前停止的依据。关于作者：梅子行，资深风控技术专家、AI技术专家和算法专家，历任多家知名金融科技公司的算法研究员、数据挖掘工程师。师承Experian、Discover等企业的资深风控专家，擅长深度学习、复杂网络、迁移学习、异常检测等非传统机器学习方法，热衷于数据挖掘以及算法的跨领域优化实践。毛鑫宇，资深品牌视觉设计师、插画设计师。曾任职国内知名文旅公司品牌设计师，设计打造知名文化旅游目的地及品牌设计案例。本文摘编自《智能风控：Python金融风险管理与评分卡建模》，经出版方授权发布。本书基于Python讲解了信用风险管理和评分卡建模，用漫画的风格，从风险业务、统计分析方法、机器学习模型3个维度展开，详细讲解了信用风险量化相关的数据分析与建模手段，并提供大量的应用实例。作者在多家知名金融公司从事算法研究多年，经验丰富，本书得到了学术界和企业界多位金融风险管理专家的高度评价。
关键词: 机器学习,  监督学习,  过拟合,  欠拟合
AI技术: 机器学习,  监督学习,  半监督学习,  无监督学习,  分类
行业: 金融科技,  风控技术,  品牌视觉设计
重大事件摘要: 这篇文章是一篇关于机器学习基础知识的详细介绍，包括了机器学习中的基本概念、模型学习过程、模型评价标准以及过拟合与欠拟合的问题。文章通过具体的例子和图示，向读者解释了特征（Feature）、标记（Label）、样例（Sample）、假设空间（Hypothesis Space）等基本概念，并介绍了监督学习、半监督学习和无监督学习三种不同的学习方式。此外，文章还讨论了模型训练过程中可能出现的欠拟合和过拟合问题，以及如何通过划分训练集和测试集来评估模型的性能。最后，文章提到了泛化误差的概念，并解释了它由偏差、方差和噪声三部分组成。

文章的重大事件包括：
1. 介绍了机器学习中的30个基本概念。
2. 解释了特征、标记、样例、假设空间等核心概念。
3. 描述了模型学习的过程，包括监督学习、半监督学习和无监督学习。
4. 讨论了模型评价的标准，包括欠拟合和过拟合的问题。
5. 引入了泛化误差的概念，并解释了它由偏差、方差和噪声组成。
6. 提供了实际的数据集例子来说明这些概念。
7. 强调了在模型训练过程中划分训练集和测试集的重要性。
8. 提到了最终模型上线前的测试集和训练集整合步骤。
9. 介绍了极端梯度提升机（XGBoost）在训练过程中的特殊需求。
10. 文章作者梅子行和毛鑫宇的背景介绍，以及他们的著作《智能风控：Python金融风险管理与评分卡建模》。
