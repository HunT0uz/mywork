标题: 戴琼海院士:规避技术安全隐忧 促进人工智能持续发展
链接: https://baijiahao.baidu.com/s?id=1815064940935557438&wfr=spider&for=pc
总结: 人民网记者 宋子节11月5日至6日，2024“国是论坛”在京举办。国务院参事、中国工程院院士、中国人工智能学会理事长戴琼海在接受人民网记者采访时表示，人工智能技术在开放通用场景中仍存在一些安全风险。规避技术安全隐忧，才能促进人工智能持续发展。“人工智能技术发展至今仍有多重安全风险值得注意，例如黑箱数据训练安全风险，黑箱依靠数据训练来支撑大模型对未来的推算，如果有人偷换数据，而后训练出来的人工智能模型可能成为敌人。”戴琼海举例说，“又如医疗数据安全风险，如果病例数据标注过程中存在错误，即便大部分数据判断正确，但涉及标注错误的区域时，人工智能的判断依然会给人类带来灾难。”此外，开放场景中的人工智能仍存在问题。“好比模式固化的自动驾驶无法规避所有事故，分析数据的系统无法结合自我认知生成结果。”戴琼海表示，“因此，进行颠覆性创新，从技术上要做到具有可解释性的人工智能模型或算法；要规避安全技术隐忧，保证数据的安全是人工智能最主要的安全；尽量开放场景，切忌降低维度，可以先将人工智能放到封闭场景，逐渐扩圈，最后使场景变为完全开放式。”(实习生王一惟对本文亦有贡献)举报/反馈
关键词: 
AI技术: 黑箱数据训练安全风险, 医疗数据安全风险, 自动驾驶, 分析数据的系统, 具有可解释性的人工智能模型或算法
行业: 医疗,  自动驾驶,  数据安全
重大事件摘要: 这篇文章报道了2024年11月5日至6日在北京举行的“国是论坛”，其中，国务院参事、中国工程院院士、中国人工智能学会理事长戴琼海在接受人民网记者采访时，讨论了人工智能技术在开放通用场景中存在的安全风险。戴琼海强调了规避技术安全隐忧的重要性，以促进人工智能的持续发展。他提到了几个具体的安全风险，包括黑箱数据训练安全风险、医疗数据安全风险以及开放场景中的人工智能问题。为了解决这些问题，戴琼海提出了进行颠覆性创新、开发具有可解释性的人工智能模型或算法、保证数据安全以及逐渐扩大人工智能应用场景的建议。
