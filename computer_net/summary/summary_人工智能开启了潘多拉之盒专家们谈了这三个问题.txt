标题: 人工智能开启了潘多拉之盒?专家们谈了这三个问题
链接: https://baijiahao.baidu.com/s?id=1778290215672413985&wfr=spider&for=pc
总结: 会议现场合影。红网时刻新闻9月28日讯（记者 陈珉颖 通讯员 王森章）通用人工智能技术（AGI）的发展将对我们人类社会的未来产生什么样的影响？随时而来的是新一轮的技术和产业革命，还是对未来人类发展不可忽视的威胁？9月24日下午，CCF YOCSEF长沙学术会员会在中南大学校计算机学院举办主题为“AGI大模型潘多拉魔盒打开：革新还是威胁？”的观点论坛。红网时刻新闻9月28日讯会议现场。与会嘉宾围绕“通用人工智能技术和大模型的发展是否开启了潘多拉之盒”“其出现与发展对人类社会究竟带来进步还是巨大威胁？”“我们应该怎么正确认识通用人工智能技术的发展”等议题展开讨论和思辨。针对人工智能领域的国际竞争，我们是应该加速大模型的研发，还是应该持更谨慎的态度，在没有扎好威胁“护栏“之前暂停或延缓开发？针对人工智能领域的国际竞争，我们是应该加速大模型的研发，还是应该持更谨慎的态度，在没有扎好威胁“护栏“之前暂停或延缓开发？部分嘉宾持比较乐观和积极的态度，认为我们国家应该积极研发，努力追赶国际先进水平。还有一部分学者认为，我们应该将科学研究与工程应用区分开来。对大模型的研究，应将其限定在科学研究领域内，而在商业应用方面要更加谨慎，努力做好“防火墙”。在将大模型服务于人民之前，需要提前做好社会实验来评估大模型潜在的危害与风险。还有嘉宾认为，相对于大模型的快速发展，我们对大模型的治理是相对滞后的，如果缺乏相关的法律法规来约束，可能带来难以预料的危害。为此，应重视大模型的研发与相应配套的监管协同发展。会议现场。AGI大模型的进一步发展是否会对人类社会的伦理、价值观等产生威胁？AGI大模型的进一步发展是否会对人类社会的伦理、价值观等产生威胁？一部分嘉宾对大模型发展出自主意识感到担忧，担心大模型产生意识后可能引导人类走向失控和混乱，进而对伦理产生影响。也有嘉宾认为，技术发展是不确定的，伦理需要跟上技术的发展，伦理和技术是相互发展相互迭代的。人类价值观和伦理系统本身不是稳固的，很多技术都在一定程度上影响了价值观。对于AI能否产生意识的问题，有部分嘉宾认为目前来看是不会产生意识，目前的AI还是很初级的阶段。不跟环境打交道是不可能产生意识的。意识其实就是一种主观体验，自然界只有人类和极个别的物种才有自我意识。目前的大模型均没有看到主观意识的影子。与会嘉宾合影。当超级AI的智能超过了人类，人类还能有效的控制超级AI吗？当超级AI的智能超过了人类，人类还能有效的控制超级AI吗？许多嘉宾都认为人工智能会超过人类智能，不管从技术和产品的角度来说都是有可能的。虽然在现在的时间点，有很多是AI仍做不到的，但这不代表后面AI是做不到的，我们不能仅仅以现在的认知来判断人工智能是否能超过人类智能，机器的进化比人类的进化要快很多。也有嘉宾指出人工智能会不会越人类智能这一问题，我们需要先搞清楚人类智能到底表现在哪一些方面。即使它超越了，它也不会消灭人类的文明。我们是生产者，为大模型的存在奠定基础。大模型是依赖于人类产生的数据，就像我们人类依赖大自然一样。举报/反馈
关键词: AGI大模型, 潘多拉之盒, 人类社会, 超级AI
AI技术: 通用人工智能技术（AGI），大模型，国际竞争，法律法规，伦理价值观。
行业: 计算机科学,  工程技术,  法律法规
重大事件摘要: 这篇文章报道了在中南大学计算机学院举办的一场关于通用人工智能技术（AGI）和大模型发展的论坛。会议讨论了AGI技术的发展可能带来的影响，包括它是否开启了潘多拉之盒、对人类社会是进步还是威胁、以及如何正确认识AGI技术的发展。与会嘉宾就是否应该加速大模型的研发、科学研究与工程应用的区分、大模型治理的法律法规需求、AGI对伦理和价值观的影响、以及超级AI是否能被人类有效控制等问题进行了深入讨论。部分嘉宾持乐观态度，认为应积极研发以追赶国际先进水平，而另一些学者则主张更谨慎的态度，强调在大模型商业应用前需做好风险评估和“防火墙”建设。此外，还有观点认为技术发展是不确定的，伦理需要跟上技术的发展，而人类智能的表现方面也需要明确，以便更好地理解AI超越人类智能的可能性。
