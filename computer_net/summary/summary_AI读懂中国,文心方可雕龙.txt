标题: AI读懂中国,文心方可雕龙
链接: https://baijiahao.baidu.com/s?id=1748156822704288510&wfr=spider&for=pc
总结: 作为中文系学生，记得在学校时候老师叮嘱有一本书一定要读，那就是《文心雕龙》。《文心雕龙》是由南朝刘勰所作，被鲁迅先生认为可以媲美亚里士多德的《诗学》。这部著作之所以宝贵，在于它根据中国文学的发展脉络，提出了文体、原道等一系列经典理论。甚至在近现代历史上，还让“中国没有自己文学理论”的说法不攻自破。《文心雕龙》的成功，向我们展示了这样一种理念：只有懂中国的内容与语言，理解中国独有的创作技巧、表达意境，才能提出符合中国的理论架构。这一点或许可以从文学推而广之，在更多与内容创作相关的领域找到依据。比如最近一段时间，AIGC异常火爆，尤其AI作画已经破圈到我身边的每个人都想试试。但在一段时间之后，我们却会发现大量海外的AI作画平台，在最终表达上似乎与中国创作者的需求有些偏差。这种问题为什么存在？又应该如何解决？《文心雕龙》千年之后，另一个“文心”跃然而出。百度刚刚发布了文心系列大模型的新作——文心ERNIE-ViLG 2.0。（ERNIE-ViLG 2.0 助力视觉内容 AI 大生产）与其他AI作画大模型相比，文心ERNIE-ViLG 2.0有两个显著的特点。首先在通用的理解能力和清晰度上更进一步，语义理解能力更强，生成的图像更高清；另外一点就是它能够更加准确地理解中文表达，也更懂中国文化。让我们借着这个很有意思、也很独特的AIGC差异化特质，聊聊文心ERNIE-ViLG 2.0的创新之路。AI笔触融华夏，文心依旧可雕龙。AI作画全球繁荣，但国人更需要基于语言与文化的理解AI作画其实并不是刚刚才兴起，但愈发出色的绘画能力，以及不断降低的门槛，让AI作画在近半年时间风靡全球，从一项“极客玩具” 彻底变成了街谈巷议的大众文化潮流。AI作画有多火？这个问题有很多答案，我们可以看到AI作画的软件、平台创业者不断增多，相关的全球投融资热度在全球科技产业放缓的局面下一枝独秀。“AI作画拿下人类大奖”“AI作画以假乱真”等消息不断破圈，主流媒体也在争相探讨AI作画会不会让人类画师感到压力。（ERNIE-ViLG 2.0在中国元素相关概念上创作的图像：仙鹤、京剧）在这种全球普遍的繁荣景象下，我们却会注意到一重潜在的“缺失”，那就是国内外蜂拥而起的AI作画产品，背后的算法能力主要是来自基于扩散生成算法的DALL-E 2和Stable Diffusion等国外模型。或许有人会认为这并没有什么问题。当然，我们也非常支持和推崇科技的全球化。但就实际应用而言，国外大模型却在AI作画上有着不够理解中国语言、文化的问题。这就像一个不通中文，也不理解中国文化的外国文学评论家，恐怕也难以写出媲美《文心雕龙》的文艺理论。（ERNIE-ViLG 2.0 创作的图像示例：令人震撼的科幻插图杰作，神秘宇宙星辰背景中出现一只巨大的星球, 大场景，无比详细，明暗对比，32k）具体到AI作画中，我们会看到AI作画的逻辑是根据文字描述生成画面，而画作又可能应用到各行业的场景当中。这就暴露出海外AI算法作为基础存在的问题。比如说：1.模型不能够充分理解中文描述，导致生成画面不够精细、准确。2.模型不能理解中国行业与应用场景的主要诉求、想法以及一般规则。这让AI作画更多停留在单纯的绘画创作阶段，难以融入中国的行业诉求与行业场景。3.模型不能准确理解中国文化，也就难以创作出针对性的作品。比如让海外AI模型创作与中国古典意境、节气、节日相关的画作，往往会产生巨大偏差。面对AI作画基础模型的空白，文心ERNIE-ViLG 2.0成为了国内首个在这一方向取得突破的工作。更懂中国文化的AI妙笔，已然成为现实。丹青妙笔，中国心魂：文心ERNIE-ViLG 2.0的多样化创新从技术创新的逻辑上看，ERNIE-ViLG 2.0带来的差异化是多方面的。首先，秉承着百度在文心大模型当中探索的知识增强方向，ERNIE-ViLG 2.0本身在AI作画的技术能力上带来了大幅的提升。目前阶段，主流AI作画大模型依旧存在一些亟待解决的问题，其中最显著的两点就是语义理解不够精细，以及图像不够清晰。这些问题的存在，依旧限制了用户对AI作画的使用上限，尤其阻碍了复杂专业场景与AI作画的结合。为此，ERNIE-ViLG 2.0采用了基于知识增强算法的混合降噪专家建模，使其成为全球首个将知识增强与AI作画相互结合的大模型。同时，ERNIE-ViLG 2.0也是全球参数规模最大的AI作画大模型。据了解，ERNIE-ViLG 2.0 在文本生成图像公开权威评测集 MS-COCO 和人工盲评上均超越了 Stable Diffusion、DALL-E 2等模型，取得了当前该领域的世界最好效果，在语义可控性、图像清晰度等方面均展现出了显著优势。（ERNIE-ViLG 2.0 创作的图像示例：凤凰周身火焰，多彩的祥云，明月，cg感）让我们具体来看，取得优秀成绩的ERNIE-ViLG 2.0是如何解决语义理解与画面精度两大通用问题的。首先，在AI作画模型的使用中，用户会特别关注语义表达是否被准确理解的问题，在生成比较复杂、多要素的画作时尤其如此。为了提升相关能力，ERNIE-ViLG 2.0通过视觉、语言等多源知识指引扩散模型学习，强化文图生成扩散模型对于语义的精确理解。基于语言和图像知识的知识增强算法，提升了ERNIE-ViLG 2.0生成图像的语义一致性和可控性。百度研究者提出了将知识增强算法融入扩散模型学习的方法，从而在扩散模型学习过程中，引入语言、视觉等多源知识，指引模型更加关注文本和图像中的核心语义元素，同时针对训练数据噪声带来的训练图文样本语义偏差问题提出了文本语义补全的方法，对图文的语义一致性进行针对性学习，进而实现精准的细粒度语义控制。另一方面，用户对AI生成画作的精细度的需求也不断提升。尤其用于行业场景，有明确指向的AI生成画作，必须保证充分可用的图像质量。在这个方面，ERNIE-ViLG 2.0首次引入基于时间步的混合降噪专家模型来提升模型建模能力，让模型在不同的生成阶段选择不同的“降噪专家”网络，从而实现更加细致的降噪任务建模，进而提升生成图像的质量。（ERNIE-ViLG 2.0 架构图）针对模型建模能力不足，导致图像质量不够好的问题，百度研究者发现，扩散模型的降噪过程中不同阶段对降噪网络的能力要求不同，初始阶段模型需要从纯随机噪声中生成图像轮廓，结尾阶段对模型的要求变为对图像细节补全，传统方法使用同一网络建模整个降噪过程，模型需要同时满足不同阶段的建模需求。为此，百度提出了针对不同阶段选择不同网络（降噪专家）进行建模的框架，可以有效解决不同阶段对模型能力要求不一致的问题，减少降噪任务的互相干扰。由于每个生成阶段只选取一个专家进行生成，实现了在不增加模型预测计算量的情况下对模型建模能力的扩充。（ERNIE-ViLG 2.0在中国元素相关概念上创作的图像：剪纸、凤凰）?接下来，就要说到我们之前着重讨论AI作画对中文、中国文化的理解问题。这个领域的能力提升诀窍，在于模型训练需要结合海量的中文图文数据。而对于海外科技公司与算法开发者来说，这样的数据储备难度太大、耗时太长，并且也缺乏足够的市场动力。而百度则在这一领域具有先天的优势。从搜索到AI，再到深度学习框架、能力与大模型的不断建设，中文图文数据都是百度AI发展的必选项和基础项。于是，百度研究者构建了近2亿规模的高质量中文图文数据对，基于知识增强的混合降噪专家建模，从而使得ERNIE-ViLG 2.0具备了强大的中文语义理解能力。最终我们可以发现，ERNIE-ViLG 2.0具有非常精准的中文理解能力，同时也对中国文化、中国元素有了充分的吸收。我们可以通过ERNIE-ViLG 2.0得到非常具有中国风、中国文化意境的画作，而这在其他模型中是很难实现的。一幅山水写文心，千行百业尽雕龙对于广大AI作画的用户与潜在用户来说，最关注的事情莫过于文心ERNIE-ViLG 2.0的使用情况与使用前景。在今天，我们可以看到AI作画正处在高速发展的黄金阶段。相信不久之后这项能力就会成为我们日常获得图像内容的基础选项，完全融入我们的生活与工作。而在这种趋势下，ERNIE-ViLG 2.0投入产业空间，服务千行百业的节奏也是非常快的。在今年8月，ERNIE-ViLG 2.0模型就通过API服务的方式对外开放。一经上线，就受到了广大开发者和爱好者的关注。尤其值得注意的是，很多国外的开发者、AI作画用户都对ERNIE-ViLG 2.0给出了非常高的评价。认为其效果远远超过目前其他的AI作画模型。甚至有国外网友感叹“最先进的 AI 动画生成技术在中国”。这又一次证明了，民族的也就是世界的。（ERNIE-ViLG 2.0 创作的图像示例：srudio ghibli风格，一个巨大的圆月、超现实的超自然村庄，抽象的生物形态建筑、白色，金色）目前阶段，AI作画相关的软件、平台高速发展，开发者非常需要具有足够强大能力的基础模型。而ERNIE-ViLG 2.0已经为广大开发者、科技爱好者提供了飞桨开源工具和API服务能力，满足开发者灵活探索等需求。对灵活性需求更高的开发者，可以使用飞桨的开源工具PaddleHub基于文图生成开源算法极简开发，并完成模型的管理和一键预测。对便捷性需求更高的开发者，可以使用文心ERNIE-ViLG API，极速获得沉浸式文图生成大模型的技术体验，更可灵活方便、高效地实现产品集成。同时，对于更多需要AI作画能力的普通用户来说，百度已经推出了基于ERNIE-ViLG 2.0大模型的AI 作画产品—— AI艺术与创意辅助平台：文心一格。目前，文心一格已经成为了我们团队小伙伴在图像内容创作方面的“辅助神器”。（ERNIE-ViLG 2.0在中国元素相关概念上创作的图像：青花瓷、建筑）紧接着，我们可以看到ERNIE-ViLG 2.0的价值不仅仅停留在目前我们可以看到的AI作画体验。它更广阔的价值在于千行百业的图像内容生成需求与整体数字化进展。在很多行业，图像设计和创作的价值都非常重要，比如工业设计、动漫设计、游戏制作、服装设计等等。ERNIE-ViLG 2.0的未来发展空间，在于与各行业的设计需求、图像升级需求相结合，成为辅助创作的效率助推器，提升相关行业的数字化、智能化水平。随着AI作画的连续破圈，我们可以看到AIGC的新纪元正在开启。这次突破一方面证明了AI技术本身具有连绵不绝的价值潜力，同时也展示了AI技术关键能力自主、自立、自强的必要性。从这个角度看，ERNIE-ViLG 2.0作为文心大模型家族的新成员，既走在潮流前沿，也走在中国智能化的大道上。AI妙笔，正在写一部新时代的“文心雕龙”。想体验更多功能，可以移步文心大模型官网。本文首发于微信公众号：脑极体。文章内容属作者个人观点，不代表和讯网立场。投资者据此操作，风险请自担。举报/反馈
关键词: 文心雕龙,  AI作画,  中国文化
AI技术: 扩散生成算法, DALL-E 2和Stable Diffusion, 基于知识增强算法的混合降噪专家建模
行业: 工业设计, 动漫设计，游戏制作
重大事件摘要: 这篇文章介绍了百度新发布的AI作画大模型文心ERNIE-ViLG 2.0，它通过结合中国语言和文化的知识增强算法，提升了在图像生成和语义理解方面的能力。以下是文章中提到的重大事件：

1. **文心ERNIE-ViLG 2.0发布**：百度发布了新的AI作画大模型文心ERNIE-ViLG 2.0，该模型在通用理解和清晰度上有所提升，并更精准地理解中文表达和文化背景。

2. **技术创新**：ERNIE-ViLG 2.0采用了基于知识增强算法的混合降噪专家建模，成为全球首个将知识增强与AI作画相结合的大模型。同时，它是目前参数规模最大的AI作画大模型之一。

3. **超越现有模型**：在文本生成图像的公开权威评测集MS-COCO和人工盲评中，ERNIE-ViLG 2.0超越了Stable Diffusion、DALL-E 2等模型，取得了当前该领域的世界最好效果。

4. **解决语义理解与画面精度问题**：ERNIE-ViLG 2.0通过多源知识指引扩散模型学习，强化了文图生成扩散模型对于语义的精确理解，并首次引入基于时间步的混合降噪专家模型来提升图像质量。

5. **中文图文数据的优势**：百度利用其在中文图文数据方面的优势，构建了近2亿规模的高质量中文图文数据对，使ERNIE-ViLG 2.0具备了强大的中文语义理解能力。

6. **产业应用**：ERNIE-ViLG 2.0已经通过API服务对外开放，并推出了AI艺术与创意辅助平台“文心一格”，服务于广大开发者和普通用户，推动各行业的图像内容生成需求和数字化进展。

7. **文化与技术的结合**：ERNIE-ViLG 2.0展示了如何将中国传统文化元素与现代AI技术相结合，创造出具有中国特色的艺术作品。

8. **国际认可**：ERNIE-ViLG 2.0受到了国内外开发者和用户的高度评价，甚至有国外网友感叹其为“最先进的AI动画生成技术在中国”。

9. **未来展望**：ERNIE-ViLG 2.0的价值不仅在于当前的AI作画体验，还在于其广阔的行业应用前景，包括工业设计、动漫设计、游戏制作、服装设计等领域。

这些事件标志着百度在AI作画领域的重大进展，以及中国文化与现代技术的深度融合。
