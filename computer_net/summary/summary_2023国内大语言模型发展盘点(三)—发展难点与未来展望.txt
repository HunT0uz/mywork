标题: 2023国内大语言模型发展盘点(三)—发展难点与未来展望
链接: https://baijiahao.baidu.com/s?id=1788219391838889700&wfr=spider&for=pc
总结: （本文作者王鹏为北京市社会科学院研究员，数据资产化研究院执行院长）在全球范围内，大型语言模型的发展正在迅速推进。国内已经具备了多个具有先进技术与创新能力的额模型，但在数据处理、技术标准以及隐私问题等方面仍然存在不容忽视的障碍。本文将深入分析中国在大型语言模型发展中所遇到的主要瓶颈，并尝试提出针对性的政策建议，以期推动国内在该领域的持续发展。一、发展难点问题分析（一）数据来源多样性与质量不足数据来源多样性与质量与大模型训练水平具有直接联系，而我国数字化进展一定程度上限制了大模型发展。其一，我国于数字化转型面临一系列问题与挑战，导致数据来源相对较少。大模型训练数据通常包含公开数据集、社交媒体与网络内容以及行业和企业数据等。澎湃新闻智库曾指出我国产业互联网行业渗透不均，例如于金融行业中，产业互联网指数达到30.22，而这一数据在制造业仅为5.5。数据结构性矛盾将反映在我国大语言模型训练过程中，可能导致模型对于特定行业、群体表现不佳，无法满足在各种情境下的应用需求。第二，伴随网络内容碎片化与封闭化，高质量数据的获取变得更加昂贵和有限。此外，虽然我国数字化转型进程较为积极，但在数据平台、高质量数据的可访问性和共享以及数据标注的质量和一致性上仍有不足。数据来源的多样性以及数据质量在中国大语言模型发展中将继续扮演重要角色。（二）模型可解释性与透明度的不足模型可解释性以及透明度的不足可能使大语言模型在训练过程中产生错误或者有偏见的结果。第一，大语言模型通常包含数百万甚至数十亿参数。庞大的模型结构使得理解模型内不决策过程变得极其复杂。第二，大型语言模型的决策过程通常不透明，模型的用户与开发者难以追踪和理解模型是如何从输入数据中提取特征并作出决策。由于国内于大语言模型起步相较美国部分领先企业较晚，总体技术与框架相较领先水平仍有一定差距，校企合作进行人才培养，相关企业的融资规模都将影响国内大语言模型的进一步发展。（三）隐私与安全问题伴随国内数据保护法律与法规日益严格，大型语言模型训练对于数据的大量需求，以及公众对于个人隐私保护的关注程度上升，隐私与安全问题日益突出。第一，在大型语言模型的训练中使用的大量数据容易涵盖个人隐私信息，例如社交媒体、论坛的数据可能包含个人身份信息。第二，数据处理与存储的安全风险需要相关存储与处理技术的配套。技术漏洞或者管理缺陷均存在威胁数据隐私的可能。此外，大模型可能被恶意使用，例如生成虚假信息散播谣言以及进行网络攻击等，相关安全问题需要监管能力的配套以及相关防范措施的出台。（四）技术标准与规范缺乏技术标准与规范作为确保系统兼容性与可靠性的基石，在大模型发展中扮演关键角色。我国缺乏相应的技术标准与规范。不同大模型之间可能存在兼容性与互操作性问题，且不同机构和组织开发的大模型之间难以形成无缝对接与集成。模型的数据处理流程、网络架构与参数配置等各方面缺乏统一标准导致无法实现“即插即用”的效果，开发者需要在对接与兼容性工作中投入巨大劳动力，降低开发效率。此外，在没有共同标准的情况下，模型的训练和测试数据格式可能大相径庭，开发者不得不编写额外的代码来转换数据，从而满足特定模型的需求。（五）人工智能伦理问题随着大模型在各个领域的广泛应用，人工智能伦理问题日益突出。在大模型的训练过程中，可能会存在数据偏见和算法歧视等问题，这些问题可能会对社会产生负面影响。数据偏见可能在模型的输出中得以体现，并进而影响到模型在现实世界的决策和判断，例如在招聘、信贷审批等重要领域中，模型的偏见可能导致对某些群体的不公平对待。这种不平等可能削弱对人工智能公正性的信任，并损害受影响群体的权益。而算法歧视可能是由于算法设计者的偏见、训练数据的不平衡或模型的不透明度所致。算法歧视不仅有损机器决策的公平性，还可能加剧社会不平等。此外，大模型被恶意使用的风险也不容忽视。由于其强大的数据处理和模式识别能力，大模型可能被用来进行网络攻击、自动化生产和传播虚假信息、深度伪造等。这些行为可能对个人隐私、社会秩序和国家安全造成威胁，这也需要加强监管和防范措施。二、未来发展展望本系列文章通过对过去一年国内大语言模型发展趋势的盘点以及与国际领先水平的对比明确了国内在大语言发展自身瓶颈。为实现国内大语言模型的更好发展，本文尝试提出未来展望：（一）亟待解决的主要难点分析数据作为大模型训练的基础，中国大模型发展需要数据来源多样性的提升以及数据质量的进一步提高。第一，着力开展数据平台的建设。尽管存在部分开放数据平台提供高质量的公开数据集，但只停留在公开数据集的层面。数据交易所和数据联盟的建立有助于提供更好的数据流通方式；第二，制定相关的政策和指南确保数据的安全和高效管理。发布技术和管理指南，帮助数据提供者和使用者遵守数据安全和隐私保护的相关法律法规。此外，定期更新政策和指南以适应技术发展和市场变化。（二）大力发展智能算力算力作为大语言模型发展的最大瓶颈之一，解决高端化智能化算力和存储能力的短板对于国内大语言模型发展至关重要。第一，尝试算法算力的重构。重点投资大型模型的核心技术领域，如算法研发、数据处理等，确保关键领域的自主创新能力。强化处理器、服务器与核心芯片等硬件系统的研发和制造能力；第二，尝试场景生态的重构。尝试将大语言模型整合至产业的各个层面，借助算力与算法为社会生活带来新工具与平台，利用大模型重构企业业务生态，推动制造业和实体经济的数字化转型，以技术创新促进业务提升和智能化机遇。（三）突破性技术创新大模型的发展需要不断创新与优化以提高模型的能行、效率以及可解释性，因此技术创新对于国内大语言发展至关重要。第一，加强企业与研究机构之间的合作，通过建立合作平台，促进企业与学术界之间的知识与资源共享。此外，设立研究基金和补贴，支持大型语言模型的创新研究和发展项目；第二，加强共享知识产权和案例的研究。通过促进知识产权共享机制的建立，降低技术转移和应用的障碍，借助案例研究共享的数字化进程，通过实例学习与实践促进技术创新。（四）隐私和安全并举伴随人工智能特别是大规模模型越来越多地渗透到医疗、金融、教育等关键领域，其对个人隐私与数据安全的潜在风险也随之增加。为应对人工智能特别是大规模语言模型在关键领域应用中的隐私和数据安全问题，可以采取以下措施确保更好的发展。第一，建立完善的数据安全管理体系。政府牵头制定和执行一套全面的数据管理规范，确保数据的收集、处理、存储和使用符合国家的法律和标准，定期对数据安全管理体系进行审核和升级，以适应不断变化的技术和威胁环境。第二，强化法律法规和监管机制。相关部门更新和完善相关的数据保护法律和法规，提供明确的指导和监管框架，加强对大型语言模型应用的监管，确保企业和研究机构遵守数据保护规定；第三，应用先进的技术防护措施，比如数据加密、匿名化处理、防火墙、入侵检测系统等，抵御外部攻击和内部泄露的威胁。（五）跨模态加速融合未来人工智能应用将需要处理多种模态的数据，如文本、图像、语音以及视频等，因此，为促进大语言模型发展，国内需要进一步加强跨模态大模型的研究与发展。第一，促进跨学科合作。政府应当出台相关政策以鼓励计算机科学、人工智能、语言学、心理学和认知科学等领域的交叉合作，共同推动跨模态大模型的发展。此外，建立跨学科研究平台和实验室，集合各领域专家专业知识共同攻克跨模态融合的技术难题。第二，推动实际应用和技术验证。在大模型应用相对成熟的行业进行跨模态大模型的实际应用试验，收集反馈并不断优化模型。将研究成果转化为实用技术和产品，推动产业升级。（六）人工智能伦理和法规不断完善伴随人工智能伦理与法规问题的日益突出，中国需要完善人工智能伦理和法规体系，规范大模型使用与管理。第一，完善相关法律法规。相关部门通过更新与完善人工智能领域的相关法律法规明确大模型卡发和应用的法律责任与界限；第二，制定专门的人工智能伦理准则。先通过加强对人工智能伦理的研究，提高对潜在伦理问题的认识和敏感性，再者制定明确人工智能伦理法则用于指导大语言模型的研发与应用。中国大语言模型的发展面临着数据多样性与质量不足、模型可解释性与透明度不足等关键挑战，为应对相关挑战并推动大语言模型在国内的发展，中国需要采取一系列积极措施，其中包括了提升数据质量和多样性、发展智能算力、促进技术创新、加强隐私和安全保护以及完善人工智能伦理和法规体系。通过如此努力，中国不仅能够提高大型语言模型的性能和应用范围，还能确保其发展符合伦理和法规要求，为社会带来更广泛和深远的积极影响。展望未来，中国在大型语言模型领域的持续投入和创新将不仅是技术领域的进步，更是对社会责任和全球协作的承诺。本文仅代表作者观点。举报/反馈
关键词: 大语言模型, 数据质量与多样性, 隐私与安全问题
AI技术: 大型语言模型, 智能算力, 跨模态大模型
行业: 金融, 制造业, 医疗
重大事件摘要: 这篇文章中的重大事件如下：

1. 数据来源多样性与质量不足：中国大语言模型的发展受到数据来源多样性和质量不足的限制。数字化转型面临挑战，导致数据来源相对较少，同时网络内容的碎片化和封闭化也使得高质量数据的获取变得更加困难。

2. 模型可解释性与透明度的不足：大型语言模型通常包含数百万甚至数十亿参数，庞大的模型结构使得理解模型内决策过程变得极其复杂。此外，国内在大语言模型起步相较美国部分领先企业较晚，总体技术与框架相较领先水平仍有一定差距。

3. 隐私与安全问题：随着国内数据保护法律与法规日益严格，大型语言模型训练对于数据的大量需求以及公众对于个人隐私保护的关注程度上升，隐私与安全问题日益突出。

4. 技术标准与规范缺乏：我国缺乏相应的技术标准与规范，不同大模型之间可能存在兼容性与互操作性问题，且不同机构和组织开发的大模型之间难以形成无缝对接与集成。

5. 人工智能伦理问题：随着大模型在各个领域的广泛应用，人工智能伦理问题日益突出。在大模型的训练过程中，可能会存在数据偏见和算法歧视等问题，这些问题可能会对社会产生负面影响。

6. 未来发展展望：为实现国内大语言模型的更好发展，本文尝试提出未来展望，包括解决数据来源多样性和质量不足的问题、大力发展智能算力、突破性技术创新、加强隐私和安全保护以及完善人工智能伦理和法规体系等措施。
