标题: 深度学习(1): 深度学习简介_cwt+深度学习-CSDN博客
链接: http://www.baidu.com/link?url=yi5856ybXclVfKrCexCM0uduEJ1sOS-tWPtT7Lu6y1IfN9sZsJFjLJyp0u31hhls1fIF1pLoU8RUoPssWAXrJjqtIUbijIp0TX3UA5dQqPK
总结: 深度学习技术己经开始渗透到每一个领域当中，使得机器学习能够实现更多的应用场景，并且极大地拓展了人工智能的领域范畴。从无人驾驶汽车、无人驾驶飞机，到生物医学的预防性诊断、病理预测，甚至是更加贴近年轻一代的电影推荐、购物指南，几乎所有领域都可以使用深度学习。3GPU的迅速发展GPU(GraphicsProcessingUnit,图形处理器)作为硬件加速器之一，通过大量图形处理单元与CPU协同工作，对深度学习、数据分析，以及大量计算的工程应用进行加速。从2007年NVIDIA公司发布了第一个支持CUDA的GPU后，GPU的应用范围不断拓展，从政府实验室、大学、企业的大型数据中心，到现今非常火热的人工智能汽车、无人驾驶飞机和机器人等嵌入式平台，GPU都发挥着巨大的作用。CUDA(ComputeUnifiedDeviceArchitecture,统一计算设备架构)。随着显卡的发展，GPU越来越强大，GPU开始主要为显示图像做优化，在计算上已经超越了通用的CPU。如此强大的芯片如果只是作为显卡就太浪费了，因此NVIDIA推出CUDA这一通用并行计算架构，该架构使GPU能够解决复杂的计算问题。3.1GPU与显卡的区别GPU只是显卡上的一个核心处理芯片，是显卡的心脏，不能单独作为外接扩展卡使用，GPU因并行计算任务较重，所以功耗较大，只能焊接在显卡的电路板上使用。显卡上都有GPU，它是区分显性能的最主要元件，显卡也叫显示适配器，分为独立显卡和主板上集成显卡，独立显卡主要由GPU、显存和接口电路构成，集成显卡没有独立显存而是使用主板上的内存。GPU是图形处理器，一般GPU就是焊接在显卡上的，大部分情况下，我们所说GPU就等于指显卡，但是实际情况是GPU是显示卡的“心脏”，是显卡的一个核心零部件，核心组成部分。它们是“寄生与被寄生”关系。GPU本身并不能单独工作，只有配合上附属电路和接口，才能工作。这时候，它就变成了显卡参考链接:&nbsp;https://baijiahao.baidu.com/s?id=1607965696317204020&amp;wfr=spider&amp;for=pc3.2GPU与CPU区别比较GPU和CPU，就是比较它们两者如何处理任务。如下图图1-9所示，CPU使用几个核心处理单元去优化串行顺序任务，而GPU的大规模并行架构拥有数以千计的更小、更高效的处理单元，用于处理多个并行小任务。CPU拥有复杂的系统指令，能够进行复杂的任务操作和调度，两者是互补关系，而不能相互代替。GPU是大规模并行架构，处理并行任务毫无疑问是非常快的，深度学习需要高效的矩阵操作和大量的卷积操作，GPU的并行架构再适合不过。简单来说，确实如此，但是为什么GPU进行矩阵操作和卷积操作会比CPU要快呢？真正原因是&nbsp;GPU具有如下特性&nbsp;：&nbsp;(1)高带宽(2)高速的缓存性能(3)并行单元多在执行多任务时，CPU需要等待带宽，而GPU能够优化带宽。举个简单的例子，我们可以把CPU看作跑车，GPU是大卡车，如下图图1-10所示任务就是要把一堆货物从北京搬运到广州。CPU（跑车〉可以快速地把数据（货物〉从内存读入RAM中，然而GPU(大卡车〉装货的速度就好慢了。不过后面才是重点，CPU(跑车）把这堆数据（货物）从北京搬运到广州｜需要来回操作很多次，也就是往返京广线很多次，而GPU(大卡车）只需要一次就可以完成搬运（一次可以装载大量数据进入内存）。换言之，CPU擅长操作小的内存块，而GPU则擅长操作大的内存块。CPU集群大概可以达到50GB/s的带宽总量，而等量的GPU集群可以达到750GB/s的带宽量。如果让一辆大卡车去装载很多堆货物，就要等待很长的时间了，因为要等待大卡车从北京运到广州，然后再回来装货物。设想一下，我们现在拥有了跑车车队和卡车车队（线程并行〉，运载一堆货物（非常大块的内存数据需要读入缓存，如大型矩阵）。我们会等待第一辆卡车，但是后面就不需要等待的时间了，因为在广州会有一队伍的大卡车正在排队输送货物（数据），这时处理器就可以直接从缓存中读取数据了。在线性并行的情况下，GPU可以提供高带宽，从而隐藏延迟时间。这也就是GPU比CPU更适合处理深度学习的原因。3.3GPU种类特别是最近几年，随着GPU处理能力的飞速进步，在2012年需要l个月才能完成的深度学习训练，在2015年只需几天即可完成。在这样的背景下，深度学习的发展恰逢其时，将会引发进一步的革新和发展。对于深度学习的加速器GPU，现在市面上主要的品牌有AMD、NVIDIA、Intel的XeonPhi，如下图所示。NVIDIA公司的GUP使用最为广泛，NVIDIA的计算加速标准库cuDNN使得工程师在CUDA平台中构建深度学习变得非常容易，而且在同一张显卡的前提下比没有使用cnDNN的速度提升5倍之多。有良好的生态。下图是NVIDIA公司的三种类型的GPU。其中，(1)&nbsp;GeForce系列面向大众，常见的有：GeForceGTX1080,GeForceGTX1080Ti,GeForceGTX2080Ti；(2)&nbsp;Tesla系列面向科学计算；(3)&nbsp;Tegra系列面向嵌入式的GPU主板。参考资料[1]图解深度学习[2]深度学习原理与实践[3]TensorFlow实战Google深度学习框架(第2版)深度学习(1):深度学习简介-知乎(zhihu.com)
关键词: 深度学习, GPU, CUDA, 并行计算
AI技术: 无人驾驶汽车, 生物医学预防性诊断, 病理预测, 电影推荐, 购物指南
行业: 无人驾驶汽车，生物医学预防性诊断，电影推荐
重大事件摘要: 这篇文章主要介绍了深度学习技术及其在各个领域的应用，以及GPU（图形处理器）在深度学习中的重要性和作用。以下是文章的几个重大事件：

1. 深度学习技术的发展和应用：深度学习技术已经开始渗透到各个领域，如无人驾驶汽车、生物医学诊断、电影推荐、购物指南等，极大地拓展了人工智能的应用领域。

2. GPU作为硬件加速器的作用：GPU通过大量图形处理单元与CPU协同工作，对深度学习、数据分析和大量计算的工程应用进行加速。

3. NVIDIA公司推出CUDA架构：随着显卡的发展，GPU越来越强大，NVIDIA推出了CUDA这一通用并行计算架构，使GPU能够解决复杂的计算问题。

4. GPU与显卡的区别：GPU是显卡上的一个核心处理芯片，不能单独作为外接扩展卡使用。显卡分为独立显卡和主板上集成显卡，独立显卡主要由GPU、显存和接口电路构成。

5. CPU与GPU的区别：CPU使用几个核心处理单元去优化串行顺序任务，而GPU的大规模并行架构拥有数以千计的更小、更高效的处理单元，用于处理多个并行小任务。两者是互补关系，而不能相互代替。

6. GPU种类：市面上主要的品牌有AMD、NVIDIA、Intel的XeonPhi。其中，NVIDIA公司的GPU使用最为广泛，其计算加速标准库cuDNN使得工程师在CUDA平台中构建深度学习变得非常容易。

7. 深度学习加速器GPU的发展：随着GPU处理能力的飞速进步，深度学习的发展恰逢其时，将会引发进一步的革新和发展。
