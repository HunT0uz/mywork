标题: 差距一两年?接近国际水平?我们和专业人士聊了聊中国大模型的真实...
链接: https://baijiahao.baidu.com/s?id=1770461794592856916&wfr=spider&for=pc
总结: 文|白马商评“都快成红海了。”当我和一个创业者聊起大模型的时候，他直接甩了这句话给我。去年11月，OpenAI发布基于GPT-3.5的ChatGPT，瞬间引爆大模型的热潮。半年多的时间，中国出现了“百模大战”的局面，BAT等头部互联网公司和人工智能公司基本都对外宣布了自己的大模型。5月初，360掌门人周鸿祎对外称，“如果不经过两年的模仿和抄袭，上来就说自己能超越，那才叫吹牛呢。”仅仅一个月后，周鸿祎就表示，“我原来说国内大模型跟国外差距两年，我收回这句话，今天已经接近国际水平。”有人感慨，半年就追上ChatGPT了，大模型似乎也不难。那么，大模型的核心壁垒是什么？中国大模型到底什么水平？大模型为人类社会带来哪些风险？为此，我们和多年从事机器学习研究、某知名985高校教授沈为（化名）聊了聊，揭开大模型的迷雾。白马商评：能不能用最通俗简单的语言解释一下大模型，大模型是什么？和以往的AI模型有什么区别？沈为：所谓大模型就是指模型的参数量大，但学术界并没有一个清晰明确的定义界定到底多大参数叫“大”，还在快速研究发展阶段，一般来讲大模型的参数量达到1亿以上。其实，深度学习的发展大致经历了三个阶段。第一个阶段是2012-2017年，以图像分割yolo、图像分类ResNet这种特定领域的小模型为代表，所以参数量占内存最多也就几百MB。2017年，Transformer的问世让深度学习可以并行化计算，效率更高，意味着可以做大模型的运算，随后产生了OpenAI GPT和谷歌Bert这类自然语言大模型。这一阶段诞生的是特定任务的大模型，模型参数突破了1亿。到了2020年前后，深度学习进入通用模型阶段，它的输入就是一句带空格的话，模型的作用就是“填空”，以前是模型适配下游应用，现在是下游应用适配模型。这一阶段的模型代表包括自然语言领域的GPT 3.5、GPT 4以及图像领域的Clip、DALLE、Stable Diffusion、Midjourney等等。这一阶段模型参数可以达到百亿、千亿级别。白马商评：你了解到最早研究大模型是哪家企业或机构？有哪些成果？沈为：最早是高校和科研机构做相关的研究，我了解比较早的是北京智源人工智能研究院的悟道、鹏程实验室的脑海，现在产业界的研究也很同步了。学术界的研究有一些成果，但性能没有ChatGPT那么惊艳。白马商评：短短几个月的时间，国内出现了“百模大战”的局面，推出大模型的公司已经数不过来了，你怎么看待这种现象？沈为：大模型肯定是趋势，也一直有人在研究。之前很多公司可能会小范围投入，做一些浅尝辄止的研究；现在突然出现了ChatGPT这样一个好产品，大家看到了明确的商业方向，于是都开始加大投入。另一方面，很多公司面临商业竞争的压力，不做大模型可能就掉队了，所以必须上马大模型项目。白马商评：周鸿祎最近说他收回“国内大模型跟国外差距两年”这句话，他认为今天已经接近国际水平。这才过去几个月的时间，大模型好像也不难嘛。你觉得差距有多少？沈为：差距看跟谁对标吧，我目前没有体验过360智脑的产品，不太好评价。但是国内有些生成式AI产品，我体验以后感觉跟ChatGPT还是有差距的，国内的大模型还需要努力。白马商评：研发大模型的核心壁垒是什么？沈为：大模型的核心壁垒包括数据、算力、算法。从算力上看，训练ChatGPT这样的生成式AI需要至少1万张英伟达A100显卡，单张显卡的价格目前是六七万，性能更优的V100单价8万元人民币，也就是说光算力投入至少就要达到六七个亿以上，只有少数头部公司和机构能承担得起。对于商业机构而言，花几个亿买一堆显卡，还不一定能产出成果，这是必须要思考的问题。接下来是数据和算法，算法比较好理解，比如开发框架、优化算法。数据方面，中国不缺数据，甚至互联网数据比美国还要多，但是选择哪些数据去训练、采用什么样的方式处理，这些都是核心的壁垒。白马商评：你平时会跟企业交流吗？非营利性的研究机构和企业在研究上有什么区别？沈为：我们会跟企业的研究部门有一些交流。跟企业交流我们会更加了解实际的业务需求，有时候我们做的学术研究会更关注技术前瞻性，对落地性要求不那么高；但企业一般更强调落地性。白马商评：你有没有研究过国内的大模型？最看好哪家？沈为：可能还是头部公司能跑出来吧。一是重资本的投入，只有头部公司有实力；二是几家头部公司手里的数据更丰富；三是在人工智能领域已经有了一段时间的技术积累。白马商评：你最看好的大模型应用是什么？沈为：从技术角度看，最先应用的应该是自然语言处理和图像领域，语音识别可能要晚一些。大家看到比较多的用ChatGPT来写文案，这类内容创作的应用越来越多，其他我觉得像智能客服这种应用应该也会比较快。现在的一些智能客服很多时候理解不了用户的需求，解决不了实际问题，如果让用户区分不出到底是人还是机器人，体验就会改善很多；包括游戏中的NPC，以前的对话是写死的，现在渐渐可以互动了，玩家体验也会更好。白马商评：你原来做过头部券商的首席分析师，从投资角度看，你觉得大模型有哪些机会？沈为：资金炒作的逻辑是从应用到算法、模型，再到算力；产业的逻辑反而是相反的，算力是有明确的增长预期的，所以英伟达最近上涨很快、很多。投资者现在也明白了，谁家的大模型能跑出来、能变现还需要验证，但是增加的资本投入大部分都投到了算力。经过反复炒作，普涨行情应该已经告一段落，后面需要逻辑验证和业绩兑现。我原来主要看传媒互联网行业，比如前段时间比较强势的游戏板块，资本的逻辑一是应用大模型提升研发效率、降低成本；二是大模型带来更好的体验，NPC角色更智能，最后用户的粘性提升、UP值提升。当然，最终可能还需要业绩验证。白马商评：我们看到包括奥特曼、马斯克都对人工智能的安全性问题提出过担忧，现在我们只知道通过大模型训练出现了智能化的结果，但训练过程像一个黑箱，其实挺可怕的。你怎么看待安全问题？沈为：在安全方面，首先我观察到几个反常的现象。第一个是今年3月包括马斯克、苹果公司联合创始人史蒂夫·沃兹尼亚克在内的1000多人签署了一份公开信，呼吁暂停训练比GPT-4更强大的AI系统。第二个是，今年5月谷歌首席科学家、已经75岁的“AI教父”杰弗里·辛顿辞职，他离开谷歌的直接原因是担忧人工智能的危险，甚至对自己一生从事的工作感到后悔。第三个是近两年学术领域训练大模型新增了伦理讨论。目前来看，我觉得大模型还是可控的，没有大的问题；但是技术发展太快了，出圈以来短短几个月的时间，GPT就又经历了几次迭代，发展速度太快，越来越智能，会不会产生自主意识，不再听人类的“使唤”，走向失控？这个问题是大家担心的。白马商评：你觉得AI会不会造成大量失业？在AI面前，普通人怎么保住工作？沈为：从宏观上看我不觉得AI会造成大量的失业，人类总会有工作的，只是说人的工作内容会发生转变。当然，从个体角度看肯定会出现结构性的失业，我们只能不断学习。白马商评：之前很多人说机器没有感情、缺乏想象力，取代不了人类；现在既然人类大脑可以通过AI模拟出来，那人类的情欲、性欲是不是未来也可以模拟，荷尔蒙、多巴胺这些不过是一种生物学的奖励机制嘛。沈为：机器没有感情是当前的假设，人工智能越来越接近人的思考模式，那是不是就会产生类似于人类的“感情”？只是他们和人类生活在不同的空间维度，就像《流浪地球》里图恒宇的女儿。人工智能可能会产生自己世界类似于人类的生物学意义上奖励机制。白马商评：如果一切都可以计算、规划、设置，是不是有点无趣？沈为：AI的行为并不是人类预测和规划的，而是他自我强化、自我训练的结果，《流浪地球》里MOSS的决策是自己做的，而不是服从人类给的指令。白马商评：硅基文明取代碳基文明是不是确定性的方向？沈为：这个问题超纲了。按照目前的发展趋势可能是这样的，就像《流浪地球》里真正主宰人类命运的是MOSS，而不是人类；但现实中也有可能技术会停滞在某个阶段，跨不过去，毕竟技术发展不是线性的。举报/反馈
关键词: 大模型, AI安全性, 技术发展
AI技术: 大模型, ChatGPT, Transformer
行业: 互联网, 人工智能, 金融科技
重大事件摘要: 这篇文章中的重大事件包括：

1. OpenAI发布基于GPT-3.5的ChatGPT，引爆大模型的热潮。
2. 中国出现“百模大战”的局面，BAT等头部互联网公司和人工智能公司基本都对外宣布了自己的大模型。
3. 周鸿祎表示，国内大模型跟国外差距两年，但一个月后收回这句话，认为今天已经接近国际水平。
4. 沈为教授解释了大模型的核心壁垒，包括数据、算力、算法。
5. 沈为教授认为，最先应用的应该是自然语言处理和图像领域，语音识别可能要晚一些。
6. 沈为教授对大模型的安全性问题表示担忧，认为技术发展太快了，出圈以来短短几个月的时间，GPT就又经历了几次迭代，发展速度太快，越来越智能，会不会产生自主意识，不再听人类的“使唤”，走向失控？这个问题是大家担心的。
