标题: 机器学习笔记--机器学习基本概念(全面总结,通俗易懂)-CSDN...
链接: http://www.baidu.com/link?url=mc0pkbU6DB6p0LpKxWTw8Pd2XJxNqI4hJLSeOW3TAFWLlbstWkJ1k-wrUpMafuFbmQ_wZ0ZQVRc-u4r4er7-hmYpsCTB7d9rN8mCyZwMk_u
总结: 文章目录前言一、什么是机器学习二、机器学习常见概念1.监督学习和无监督学习2.半监督学习、弱监督学习、强化学习3.欠拟合和过拟合4.损失和优化5.激活函数三、相关博客推荐前言  什么是机器学习？本文主要介绍了机器学习中的常见概念，包括监督学习和无监督学习、半监督学习、弱监督学习、强化学习、欠拟合和过拟合、损失和优化的概念以及常用的激活函数等。一、什么是机器学习机器学习：通过从经验中学习，使计算机能够从数据中提取出规律、模式和知识，并利用这些知识来做出预测、做出决策或执行任务，而无需明确地编程规则。二、机器学习常见概念1.监督学习和无监督学习1.1监督学习定义:提供输入数据和其对应的标签数据，然后搭建一个模型，模型经过训练后准确的找到输入数据和标签数据之间的最优映射关系，从而对新的未标记数据进行预测或分类。  定义看懵逼了吧？接下来说人话！！！  假如有一群草泥马和牛马组成的马群，这时候需要一个机器对马群进行分类，但是这个机器不知道草泥马和牛马长什么样儿，所以我们首先拿一堆草泥马和牛马的照片给机器看，告诉机器草泥马和牛马长什么样儿。机器经过反复的看，形成肌肉记忆，可以对草泥妈和牛马形成自己的定义，然后机器就可以准确的对马群进行分类。在这个过程中，草泥马和牛马的照片就叫做标签，反复的看理解为训练，形成的肌肉记忆叫做模型，这就是监督学习的过程。监督学习主要包括：线性回归、逻辑回归、决策树、随机森林、支持向量机、朴素贝叶斯、k近邻算法。1.2无监督学习定义:训练数据只包含输入样本，没有相应的标签或目标。包装一下：我们没有拿草泥马和牛马的照片对机器进行系统的训练，机器也不知道这两个马儿长什么样，而是直接让机器对这两个马儿进行分类。这就是无监督学习。  如图1所示，左图是无监督学习的过程，虽然数据被分成了两类，但是没有对应的数据标签，统一用蓝色的圆点表示，这更像是把具有相同的特征的数据聚集在一起，所以无监督学习实现分类的算法又叫做聚类。右图是监督学习中二分类的过程，标签在图中体现为三角和圆。无监督学习主要包括：聚类、PCA、关联规则挖掘。2.半监督学习、弱监督学习、强化学习半监督学习：利用同时包含标记样本和未标记样本的数据进行训练。弱监督学习：标签信息不完整或不准确的监督学习问题。强化学习：通过与环境的交互学习来做出决策和执行动作，以最大化累积奖励。3.欠拟合和过拟合3.1欠拟合：机器学习模型对训练数据的拟合程度不足或不够好的情况。  如图所示是房屋的大小和价格的关系，左图是正常的数据对应关系。右图就是一个欠拟合模型，这个模型虽然捕获了部分的数据对应关系，但是对新的数据不能很好的预测，如果输入的新数据的真实价格在改模型上下抖动，那么相同面积房屋的预测价格和真实价格会有较大的误差。解决办法：增加模型的复杂度：可以尝试增加模型的层数、增加神经元的数量或增加模型的参数量。收集更多的训练数据：增加训练数据量可以提供更多的信息。特征工程：通过特征选择、特征变换等方法，提取更有效的特征，有助于提高模型的表达能力。正则化：通过添加正则化项（如L1正则化、L2正则化）来限制模型的复杂度。模型集成：使用多个模型进行集成，如Bagging、Boosting等方法，可以提高模型的预测能力。3.2过拟合：模型过度学习了训练数据中的噪声和细节，导致对训练样本的拟合过于精确；  如图所示是房屋的大小和价格的关系，左图是正常的数据对应关系。右图就是一个过拟合模型，我们通俗易懂的理解一下，就是群众当中有坏人，有一些大大的显眼包，那就是噪声数据。噪声数据严重偏离既定的数据轨道，拟合出来的模型会发生巨大的改变，一颗老鼠屎坏了一锅汤。解决办法：增加训练数据：增加更多的训练样本可以提供更多的信息。使用正则化：通过添加正则化项（如L1正则化、L2正则化）来限制模型的复杂度。提前停止（EarlyStopping）：在训练过程中监控模型在验证集上的性能，当性能不再提升时停止训练，避免过拟合。4.损失和优化4.1损失：模型得到的预测值和真实值的差距。常见损失函数：均方误差函数（MSE）：计算预测值与真实值之间差异的平方，并求取这些平方差的平均值。均方根误差函数（RMSE）：均方误差的平方根。平均绝对误差函数（MAE）：计算预测值与真实值之间差异的绝对值，并求取这些绝对值的平均值4.2优化：尽可能在不过拟合的情况下降低损失值。  机器学习中最常用的是一阶优化函数，典型的包括GD、SGD、Momentum、Adagrad、Adam等。一阶优化函数在优化过程中求解的是参数的一阶导数值。常见优化函数：梯度：多元函数的各个参数求得的偏导数以向量的形式展现出来，这就是多元函数的梯度。梯度下降：通过迭代更新参数，沿着负梯度方向（即损失函数对参数的偏导数）逐步降低损失函数的值，直到达到局部最优或全局最优。梯度下降算法的步骤如下：初始化模型参数：根据具体问题，初始化模型的参数，如权重和偏置。计算损失函数：使用当前参数值计算损失函数的值，衡量模型预测结果与真实值之间的差异。计算梯度：计算损失函数对每个参数的偏导数，得到参数的梯度。梯度表示了损失函数在当前参数值处的变化率和方向。更新参数：根据学习率（learningrate）和梯度的方向，更新模型的参数。学习率控制了每次参数更新的步长，一般取一个较小的正数。重复步骤2至4：反复迭代执行步骤2至4，直到达到停止条件，如达到最大迭代次数或损失函数的变化不再显著常见梯度下降算法：批量梯度下降（BatchGradientDescent）：在每次迭代中，使用所有训练样本计算损失函数和梯度，并更新参数。随机梯度下降（StochasticGradientDescent）：在每次迭代中，随机选择一个训练样本计算损失函数和梯度，并更新参数。相比批量梯度下降，随机梯度下降的计算效率更高，但可能导致参数更新的方向不稳定。小批量梯度下降（Mini-batchGradientDescent）：在每次迭代中，随机选择一小批训练样本计算损失函数和梯度，并更新参数。小批量梯度下降综合了批量梯度下降和随机梯度下降的优点，既能保持较稳定的参数更新方向，又能提高计算效率。5.激活函数激活函数：将线性模型转化为非线性模型。为什么要用激活函数？举例说明：  假如有一个单层神经网络模型：  如果搭建二层神经网络，加入激活函数的二层神经网络表达式如下：  如果是一个多层次的神经网络模型，比如一个三层神经网络模型，并且每层的神经输出都使用相同的激活函数，表达式如下  可以看出，无论我们加深多少层，它仍旧是一个线性模型，如果不引入激活函数，线性模型在应对非线性问题会存在很大的局限性，所以要引入激活函数得到复杂多变的深度神经网络，从而解决更复杂的问题。以下是几个常见的激活函数：1.Sigmoid函数：常用于二分类问题或需要将输出限制在0到1之间的场景。  公式  图像  范围：Sigmoid函数的输出范围在0到1之间，可以将其视为概率值。2.双曲正切函数（Tanh函数）：常用于二分类问题或需要将输出限制在-1到1之间的场景。  公式  图像  范围：Tanh函数的输出范围在-1到1之间，相对于Sigmoid函数，Tanh函数曲线更加对称。3.ReLU函数（RectifiedLinearUnit）：深度神经网络主流激活函数。  公式  图像  范围：ReLU函数在输入大于0时输出等于输入值，而在输入小于等于0时输出为0。它的主要优点是计算简单，不会引入梯度消失问题。4.LeakyReLU函数：对ReLU函数的改进，用于解决ReLU函数在输入小于等于0时输出为0的问题。  公式  图像5.Softmax函数：常用于多分类问题，可以将神经网络的输出转化为概率分布。  公式  范围:Softmax函数对每个输入进行指数运算，然后将结果归一化，使得所有输出值的和为1。三、相关博客推荐机器学习笔记–监督学习和无监督学习全面总结（原理、示意图、代码）文章知识点与官方知识档案匹配，可进一步学习相关知识OpenCV技能树首页概览29612人正在系统学习中
关键词: 监督学习, 无监督学习, 激活函数, 梯度下降
AI技术: 机器学习, 监督学习, 无监督学习, 半监督学习, 强化学习
行业: 机器学习,  深度学习,  数据挖掘
重大事件摘要: 这篇文章是一份关于机器学习基本概念的全面总结，旨在以通俗易懂的方式介绍机器学习中的一些关键概念。文章首先定义了机器学习，即通过经验学习使计算机能够从数据中提取规律、模式和知识，并利用这些知识做出预测或决策。接着，文章详细介绍了监督学习和无监督学习的概念，以及它们在实际应用中的例子。此外，还提到了半监督学习、弱监督学习和强化学习等其他类型的学习方法。

文章进一步探讨了欠拟合和过拟合问题，这是机器学习中两个常见的问题，分别指的是模型对训练数据的拟合程度不足或过度。为了解决这些问题，文章提出了一些解决方案，如增加模型复杂度、收集更多训练数据、特征工程和使用正则化等。

最后，文章讨论了损失函数和优化算法的重要性，介绍了几种常见的损失函数和优化算法，如梯度下降及其变种（随机梯度下降、小批量梯度下降）。此外，还简要介绍了激活函数的作用和几种常见的激活函数，如Sigmoid、Tanh、ReLU、LeakyReLU和Softmax函数。

总的来说，这篇文章为读者提供了一个关于机器学习基本概念的全面概述，包括不同类型的学习方法、常见问题及其解决方案、损失函数和优化算法，以及激活函数的作用和类型。
