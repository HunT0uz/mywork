标题: 斯坦福大学“AI年度指数报告”:AI已在基本任务上战胜人类,是时候...
链接: https://baijiahao.baidu.com/s?id=1796584795914981781&wfr=spider&for=pc
总结: 美国斯坦福大学人工智能研究所15日发布的一份“AI年度指数报告”显示，AI的发展速度远远超过预期，甚至在几年前设置的衡量标准已经不再适用，很多指标的“满分线”已被AI突破。报告显示，在图像识别、阅读理解、简单运算、多语言互译等较为基础的任务上，AI已经全面超越人类水平，可以进行大规模运用。斯坦福大学的学者们认为，是时候让AI挑战更加困难的任务，发挥更大的潜力了。目前，AI在竞赛级别的数学问题以及更高难度的抽象推理演绎上还没有战胜人类最聪明的大脑，科学家们认为这应该成为AI下一步努力的方向。▲美国斯坦福大学 据视觉中国AI发展迅速AI发展迅速多项功能已超越人类多项功能已超越人类斯坦福大学的年度人工智能指数于2017年首次发布，由一群学术界和工业界的专家合力编制，旨在评估AI领域的技术能力、成本、伦理等因素，为研究人员、政策制定者和广大公众提供指引。该指数的主编内斯特·马斯雷说：“在以前，我们编制的基准测试可以用很多年，但现在AI很快就打破了我们的基准线，不得不重新为AI设定衡量标准。”报告显示，AI在“语言”“数学”等科目的基础层面已经超过人类，现在唯一有所欠缺的是“视觉空间的常识推理”（即文生视频）、“竞赛级数学解题”。马斯雷认为，AI的下一步发展应该着重加强更高层面的抽象推理能力，这样能使AI的能力比现在更上一个台阶。不过对于学习能力超强的AI来说，要理解更难更复杂的事物也并非难事。纽约大学机器学习研究员大卫·莱恩带领的团队设计了一套“GPQA测试”，被业内公认为是衡量AI综合能力的标杆。一般来说，对于人类博士生而言，参加本专业领域GPQA测试的得分率约为65%，参加其他领域的GPQA测试则平均只能得到34%的分数。截至2023年底，各家AI模型参加GPQA测试的得分率都在30%至40%之间。不过大卫·莱恩表示，今年推出的Claude 3大模型的得分率约为60%，几乎可以追上博士生在本领域的知识水平了。“这种进步速度让很多人感到震惊，包括我在内，这说明要制定一套能使用几年以上的测试标准是相当困难的”。▲AI的理解能力与日俱增“千模大战”背后“千模大战”背后AI监管仍无成熟标准AI监管仍无成熟标准2011年通常被认为是人工智能发展的起点。在知名编程网站Github上，2011年该网站共有800个和人工智能相关的项目，如今这个数字是180万。AI发展速度之所以如此之快，很大程度上也是因为广阔的商业化前景让很多科技企业嗅到了商机，2023年业界对AI相关项目的投资规模比2022年高出八倍。商业的介入加快了科研的进程，有报告统计，在全球51个较为主流的AI大模型中，只有15个是由高校里的学术团队完成，而大部分主流大模型都是由企业创造的。在激烈的竞争中，训练AI模型的成本也水涨船高。OpenAI的GPT-4训练据估计耗费了价值7800万美元的计算资源，而谷歌Gemini Ultra的训练成本则高达1.91亿美元。可以作为对比的是，2017年发布的Transformer模型训练成本仅为900美元，2019年发布的RoBERTa Large训练成本约为16万美元。此外随着版权纠纷、隐私安全等问题逐渐凸显，目前AI业界严重缺乏标准化的安全评估方法。OpenAI、谷歌和Anthropic等行业领先企业分别使用不同的测试来评估他们的模型安全性，使得人们难以横向对比AI模型的风险和局限性，给监管带来困难。由于信息不透明，加上技术门槛过高，使得公众对于飞速发展的AI担忧多过乐观。皮尤研究中心的数据显示，有52%的美国人表示对AI“忧大于喜”，这一比例高于2022年的38%。红星新闻记者 郑直编辑 何先锋 责编 冯玲玲（下载红星新闻，报料有奖！）举报/反馈
关键词: AI年度指数报告, 竞赛级数学解题, 抽象推理能力
AI技术: 图像识别、阅读理解、简单运算
行业: 人工智能, 科技企业, 版权纠纷
重大事件摘要: 这篇文章报道了斯坦福大学人工智能研究所发布的“AI年度指数报告”。报告显示，AI的发展速度远超预期，在图像识别、阅读理解、简单运算、多语言互译等基础任务上已全面超越人类水平。斯坦福大学的学者们认为，AI应该挑战更困难的任务，如竞赛级别的数学问题和更高难度的抽象推理演绎。此外，文章还提到了AI监管的问题，指出目前AI业界缺乏标准化的安全评估方法，给监管带来困难。
