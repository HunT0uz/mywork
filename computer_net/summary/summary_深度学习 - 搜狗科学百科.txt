标题: 深度学习 - 搜狗科学百科
链接: http://www.baidu.com/link?url=SAwo6Xd5VEE6yc33GI3dNNnF6tmHOl4Fpsg8-jy2OYFZ9mQSw_8gdhJIR3kfYGopJ65dTW4FVdycVk-AtWhQszyPyGWGc8_BGRcg5fa5PhkcSUAVgi0gz4z-ofsGKOkAI_8ekh3kWpxGFltxXEVjUOdlzYXbwUHgrtzhdes2bhnBc2K4Z1ChYbatzvpXRC2Wzl-EqdRf__lKt8f_FgsgIK
总结: TheWaybackMachine-https://baike.sogou.com/kexue/d10438.htm网页微信知乎图片视频医疗科学汉语问问更多»创建深度学习编辑深度学习（也称为深度结构化学习或分层学习）是基于人工神经网络的更广泛的机器学习方法族的一部分。学习可以是有监督的、半监督的或无监督的。[1][2][3]深度学习架构，例如深度神经网络、深度信念网络、循环神经网络和卷积神经网络，已经被应用于包括计算机视觉、语音识别、自然语言处理、音频识别、社交网络过滤、机器翻译、生物信息学、药物设计、医学图像分析、材料检查和棋盘游戏程序在内的领域，在这些领域中，它们的成果可与人类专家媲美，并且在某些情况下胜过人类专家。[4][5][6]神经网络受到生物系统中信息处理和分布式通信节点的启发。人工神经网络与生物大脑有各种不同。具体而言，神经网络往往是静态和象征性的，而大多数生物的大脑是动态(可塑)和模拟的。[7][8][9]目录编辑1定义2概览3解释4历史4.1深度学习革命5神经网络5.1人工神经网络5.2深度神经网络6应用6.1自动语音识别6.2图像识别6.3视觉艺术处理6.4自然语言处理6.5药物发现和毒理学6.6客户关系管理6.7推荐系统6.8生物信息学6.9医学图像分析6.10手机广告6.11图像恢复6.12金融欺诈检测6.13军队7与人类认知和大脑发育的关系8商业活动9批判和议论9.1理论9.2错误9.3网络威胁10参考文献1定义编辑深度学习是一类机器学习算法：[10]使用多个层逐步从原始输入中逐步提取更高级别的特征。例如，在图像处理中，较低层可以识别边缘，而较高层可以识别对人类有意义的部分，例如数字/字母或面部。2概览编辑大多数现代的深度学习模型基于人工神经网络，特别是卷积神经网络（CNN），尽管它们也可以包括命题公式或在深度生成模型中逐层组织的潜变量，例如深度信念网络和深度玻尔兹曼机中的节点。[11]在深度学习中，每一级学习将其输入数据转换成稍微抽象和复合的表示。在图像识别应用中，原始输入可以是像素矩阵；第一代表层可以提取像素并编码边缘；第二层可以组成和编码边缘排列；第三层可以编码鼻子和眼睛；并且第四层可以识别包含人脸的图像。重要的是，深入的学习过程可以学习将哪些特征放在哪个级别上是最优的。(当然，这并不能完全避免需要手动调整；例如，不同的层数和层大小可以提供不同程度的抽象。)[1][12]“深度学习”中的“深度”是指数据转换的层数。更准确地说，深度学习系统有一个实质的信用分配路径（CAP）深度。CAP是从输入到输出的转换链。CAP描述了输入和输出之间潜在的因果关系。对于前馈神经网络，CAP的深度是网络的深度，等于隐藏层的数量加上1(因为输出层也是参数化的)。对于递归神经网络，其中信号可能不止一次地通过一个层传播，CAP深度可能是无限的。[2]没有普遍认同的深度阈值将浅层和深度学习区分开来，但是大多数研究者认同深度学习中的CAP深度&gt;2。深度为2的CAP已被证明是一个通用逼近器，因为它可以模拟任何函数。除此之外，更多的层不会增加网络的函数逼近能力。深度模型（CAP&gt;2）能够提取比浅层模型更好的特征，因此，额外的层有助于学习特征。深度学习架构通常是用贪婪逐层方法构建的。深度学习有助于理清这些抽象概念，并找出哪些特性可以提高性能。[1]对于监督学习任务，深度学习方法通过将数据转换成类似于主成分的紧凑中间表示，并导出消除冗余表示后的分层结构，从而避免了特征工程。深度学习算法可以应用于无监督的学习任务。这是一个重要的好处，因为未标记的数据比标记的数据更丰富。可以无监督方式训练的深层结构的例子有神经历史压缩器[13]和深度信念网络。[1][14]3解释编辑深度神经网络通常用万能近似定理或者概率推理[10][11][1][2][14][15][16]来解释。[17][18][19][20][21][22]经典的万用近似定理关注具有有限大小的单个隐藏层的前馈神经网络逼近连续函数的能力。[17][18][19][20][21]1989年，乔治·赛本科发表了关于sigmoid激活函数的首个证明[18]，库尔特·霍尼克在1991年将其推广到前馈多层体系结构。[19]深度神经网络的万用近似定理涉及有限宽度但深度可增长的网络的容量。Lu等人[22]证明了如果具有ReLU激活的深度神经网络的宽度严格大于输入维数，则网络可以近似任何勒贝格可积函数；如果宽度小于或等于输入维数，那么深度神经网络不是一个通用逼近器。概率解释[15]源自机器学习领域。它的特点是推理，[10][11][1][2][14][15]以及分别与拟合和泛化相关的训练和测试的优化概念。更具体地说，概率解释将非线性激活函数视为累积分布函数。[15]概率解释导致在神经网络中引入损失作为正则化。[23]概率解释由霍普菲尔德、维卓尔和纳伦德拉等研究人员引入，并在毕晓普等人的调查中得到推广。[24]4历史编辑深度学习这个术语由RinaDechter于1986年引入机器学习社区，[25][13]伊戈尔·艾森堡和他的同事于2000年在布尔阈值神经元的背景下引入人工神经网络。[26][27]AlexeyIvakhnenko和帕拉在1965年发表了第一个用于监督的、深度的、前馈的多层感知器的通用工作学习算法。[28]1971年的一篇论文描述了一个由数据处理算法的分组方法训练的8层深度网络。[29]其他深度学习工作架构，特别是那些为计算机视觉而构建的架构，始于1980年由福岛国彦引入的神经认知机。[30]1989年，扬·勒丘恩等人对深度神经网络应用了标准的反向传播算法，这种算法自1970年以来一直是自动微分的反向模式，[31][32][33][34]目的是识别邮件上手写的邮政编码。算法工作需要3天的训练。[35]到1991年，这种系统被用于识别孤立的二维手写数字，而识别三维物体是通过将二维图像与手工制作的三维物体模型相匹配来完成的。翁等人提出人脑并不使用单一的三维对象模型，1992年，他们发表了Cresceptron，[36][37][38]一种在复杂场景中进行三维物体识别的方法。因为它直接使用自然图像，Cresceptron开启了自然3D世界的通用视觉学习。与神经认知机相似，Cresceptron是一多层的级联。但是，虽然神经认知机需要人类程序员手工合并特征，Cresceptron却在没有监督的情况下在每一层中学习了大量的特征，其中每个特征都由卷积核表示。Cresceptron通过网络进行反分析，从杂乱的场景中分割出每个学习对象。最大池化(Maxpooling)现在经常被深度神经网络采用(例如图像网测试)，最早在Cresceptron中通过级联用来将位置分辨率降低(2x2)到1倍，以便更好地泛化。1994年，安德烈德·卡瓦略与迈克·法尔赫斯特和大卫·比塞特一起发表了多层布尔神经网络（也称为失重神经网络）的实验结果，该网络由三层自组织特征提取神经网络模块(SOFT)和多层分类神经网络模块（GSN）组成，并经过独立训练。特征提取模块中的每一层提取的特征与前一层相比更加复杂。[39]1995年，布兰登·弗雷证明，使用由彼得·达扬和辛顿共同开发的唤醒睡眠算法，可以训练(超过两天)一个包含六个全连接的层和数百个隐藏单元的网络。[40]许多因素导致了速度的缓慢，包括SeppHochreiter在1991年分析的梯度消失问题。[41][42]由于人工神经网络的计算成本和对大脑如何连接生物网络缺乏理解，使用特定任务的手工特征（如Gabor滤波器和支持向量机）的简单模型在20世纪90年代和2000年代是一个流行的选择。人工神经网络的浅层和深度学习(如循环网络)经历了多年的探索。[43][44][45]这些方法从未优于非均匀内部手工高斯混合模型/隐马尔可夫模型（HMM）技术，它们基于区别训练的语音生成模型。包括梯度递减[41]和神经预测模型中的弱时间相关结构在内的[46]关键困难也已经得到分析。[47][48]另外的困难是缺乏训练数据和有限的计算能力。大多数语音识别研究人员从神经网络转向了生成模型。一个例外是20世纪90年代末的斯坦福国际研究院（SRIInternational）。在美国国家安全局和美国国防部高级研究计划局的资助下，SRI研究了语音和说话人识别中的深度神经网络。Heck的说话人识别团队在1998年的国家标准与技术研究所说话人识别评估中，首次在语音处理中使用深度神经网络取得了重大成功。[49]虽然SRI在说话人识别中使用深度神经网络取得了成功，但在语音识别中却没有取得类似的成功。在20世纪90年代后期的“原始”谱图或线性滤波器组特征的深度自动编码器的架构中，首次成功地探索到将“原始”特征提升到手工优化之上的原理，[49]并表现出它优于包含光谱图固定变换阶段的Mel-Cepstral特征。语音、波形的原始特征后来产生了大规模卓越成果。[50]语音识别的许多方面被一种叫做长短期记忆(LSTM)的深度学习方法所取代，这是一种由霍克雷特和施密休伯在1997年发表的循环神经网络。[51]LSTM神经网络避免了梯度消失问题，可以学习“非常深入学习”任务[2]，这需要对之前发生的几千个离散时间步长的事件进行记忆，这对语音识别很重要。2003年，LSTM开始在某些特定任务上与传统的语音识别器竞争。[52]后来，它与联结主义时间分类(CTC)相结合[53]为成堆的LSTM循环神经网络。[54]据报道，在2015年，谷歌的语音识别通过CTC的LSTM产生了49%的惊人性能提升，并将它用于Google语音搜索。[55]2006年，杰夫·辛顿、鲁斯兰·萨拉赫丁诺夫、奥辛德罗和特赫的出版物[56][57][58]展示了多层前馈神经网络如何有效地一次预训练一层，依次将每层视为无监督的受限玻尔兹曼机，然后使用有监督的反向传播对其进行微调。[59]他们的论文参考了《learningfordeepbeliefnets》。深度学习是各学科最先进系统的一部分，特别是计算机视觉和自动语音识别(ASR)。TIMIT（ASR）和MNIST（图像分类）等常用评估集以及一系列大词汇量语音识别任务的结果都在稳步改善。[60][61][62]ASR中的卷积神经网络被CTC取代[53]为LSTM。[51][55][63][64][65][66][67]但是在计算机视觉方面取得了更大成功。据扬·勒丘恩称，行业中深度学习的影响始于21世纪初，当时CNN已经处理了大约10%至20%的美国手写支票。[68]深度学习在大规模语音识别中的产业应用始于2010年左右。2009年NIPS语音识别深度学习大会[69]的动机是深层语音生成模型的局限性，以及给定更强力的硬件和大规模数据集使得深层神经网络（DNN）变实用的可能性。人们认为，使用深层信念网络（DBN）的生成模型预先训练深度神经网络将克服神经网络的主要困难。[70]然而，当使用具有大的上下文相关输出层的深度神经网络时，发现用大量训练数据代替预训练用于直接反向传播，产生的错误率大大低于当时最先进的高斯混合模型(GMM)/隐马尔可夫模型(HMM)，也低于更先进的基于生成模型的系统。[60][71]这两种系统产生的识别错误的性质是不同的，[72][69]这为如何将深度学习集成到所有主要语音识别系统部署的现有高效运行语音解码系统中提供了技术见解。[10][73][74]2009-2010年左右的分析对比了GMM（和其他生成性语音模型）和DNN模型，刺激了早期产业对语音识别深度学习的投资，[72][69]最终导致该行业的普遍和主导使用。这一分析是在判别性DNN和生成性模型之间进行的，他们具有相当的性能（错误率不到1.5%）。[60][72][70][75]2010年，研究人员基于决策树构造的上下文相关隐马尔可夫模型，采用DNN的大输出层，将TIMIT的深度学习扩展到大词汇量语音识别。[76][77][78][73]硬件的发展使人们重新燃起了兴趣。2009年，英伟达参与了所谓的深度学习“大爆炸”，因为深度学习神经网络是由英伟达图形处理单元(GPU)训练的。[79]那一年，谷歌大脑使用英伟达GPU创建了高性能深度神经网络。其中吴恩达确定GPU可以将深度学习系统的速度提高大约100倍。[80]具体而言，GPU非常适合机器学习中涉及的矩阵/向量数学。[81][82]GPU能将训练算法的速度提高几个数量级，将运行时间从数周缩短到数天。[83][84]专用硬件和算法优化可用于高效处理。[85]4.1深度学习革命深度学习是机器学习的一个子集，机器学习是人工智能的子集2012年，达尔领导的团队利用多任务深层神经网络预测一种药物的生物分子靶并以此赢得了“默克分子活性挑战”。[86][87]2014年，霍克雷特的团队利用深度学习来检测营养素、家用产品和药物中环境化学品的脱靶和毒性效应，并赢得了美国国家卫生研究院、美国食品和药物管理局和NCATS的“Tox21数据挑战”。[88][89][90]从2011年到2012年，深度学习在图像或物体识别方面产生了显著的额外影响。虽然通过反向传播训练的卷积神经网络已经出现了几十年，GPU实现的网络也已经出现了几年，包括卷积伸进网络，但要在计算机视觉上取得进展，还需要以Ciresan和同事的方式在GPU上实现最大池化的快速网络。[81][82][35][91][2]2011年，这种方法首次在视觉模式识别竞赛中实现了惊人的表现。同为2011年，它赢得了ICDAR中文手写比赛，并在2012年5月赢得了ISBI图像分割比赛。[92]直到2011年，卷积神经网络还没有在计算机视觉会议上大展拳脚，但在2012年6月，Ciresan等人在CVPR的主要会议上发表了一篇论文[4]说明了如何在GPU上最大限度地汇集CNN可以显著改善许多视觉基准记录。2012年10月，克里兹夫斯基等人提出了一个类似的系统。[5]在大规模的图像网竞赛中以绝对优势战胜了浅层机器学习方法。2012年11月，西雷森等人的系统还在ICPR癌症检测大型医学图像分析竞赛中胜出，并在第二年赢得了同一主题的MICCAI大挑战。[93]在2013年和2014年，使用深度学习的图像网任务的错误率进一步降低，这与大规模语音识别的趋势相近。沃尔夫勒姆图像识别项目公布了这些改进。[94]然后，图像分类被扩展到更具挑战性的任务，为图像生成描述（字幕），通常是由CNN和LSTM的组合进行。[95][96][97][98]一些研究人员估计，2012年10月图像网的胜利标志着一场“深度学习革命”的开始，这场革命改变了人工智能行业。[99]2019年3月，约书亚·本希奥、杰弗里·辛顿和扬·勒丘恩因概念和工程突破而被授予图灵奖，这些突破使深度神经网络成为计算的关键组成部分。5神经网络编辑5.1人工神经网络人工神经网络（ANN）或联结系统是由构成动物大脑的生物神经网络启发的计算系统。这种系统通过考虑示例来学习（逐步提高它们的能力）完成任务，通常不需要特定任务的编程。例如，在图像识别中，他们可以通过分析手动标记为“猫”或“没有猫”的示例图像，并使用分析结果来识别其他图像中的猫，从而学会识别包含猫的图像。它们大多数使用于很难用传统的基于规则编程的计算机算法来表达的应用。人工神经网络基于被称为人造神经元的连接单元的集合（类似于生物大脑中的生物神经元）。神经元之间的每个连接(突触)都可以向另一个神经元传递信号。接收（后突触）神经元可以处理信号，然后向与之相连的下游神经元发送信号。神经元可能有状态，通常用实数表示，一般在0和1之间。神经元和突触的权重也可能随着学习的进行而变化，这会增加或减少它向下游发送的信号的强度。通常，神经元是分层组织的。不同的层可以对它们的输入执行不同种类的转换。信号可能在多次穿过这些层之后从第一（输入）层传播到最后一个（输出）层。神经网络方法的起初目的是像人脑一样解决问题。随着时间的推移，重心集中在匹配特定的思维能力上，导致与生物学的偏差，例如反向传播，或者以相反的方向传递信息，并调整网络以反映这些信息。神经网络已经用于各种任务，包括计算机视觉、语音识别、机器翻译、社交网络过滤、棋盘和视频游戏以及医学诊断。截至2017年，神经网络通常有几千到几百万个单元和几百万个连接。尽管这个数字比人脑中的神经元数量少几个数量级，但这些网络可以在超出人类水平的水平上执行许多任务（例如，人脸识别，下围棋[100])。5.2深度神经网络深度神经网络（DNN）是一个在输入层和输出层之间有多层的人工神经网络。[11][2]DNN找到了将输入转化为输出的正确数学操作，无论是线性关系还是非线性关系。网络遍历各层并计算每个输出的概率。例如，被训练识别狗品种的DNN将检查给定的图像，并计算图像中的狗是某个品种的概率。用户可以查看结果并选择网络应显示的概率（高于某个阈值等）并返回建议的标签。每一个这样的数学操作都被认为是一个层，而复杂的DNN有许多层次，因此被称为“深度”网络。DNN可以模拟复杂的非线性关系。DNN架构生成组合模型，其中对象被表示为图元的分层组合。[101]额外的层使得能够从较低层合成特征，用比执行类似操作的浅层网络更少的单元来建模复杂数据。[11]深层架构包括一些基本方法的许多变体。每个架构都在特定领域取得了成功。除非对相同的数据集进行了评估，否则不可能总能比较多个体系结构的性能。DNN是一种典型的前馈网络，数据从输入层流向输出层而不返回。首先，DNN创建了一个虚拟神经元的映射，并为它们之间的联系分配随机数值或者说“权重”。权重和输入相乘，返回0到1之间的输出。如果网络不能准确识别特定模式，算法会调整权重。[102]这样，算法可以使某些参数更有影响力，直到它确定正确的数学操作来完全处理数据。循环神经网络（RNN）中数据可以向任何方向流动，用于诸如语言建模的应用。[103][104][105][106][107]长短期记忆在这方面特别有效。[51][108]深度卷积神经网络用于计算机视觉。[109]CNN也被用于自动语音识别（ASR）的声学建模。[67]挑战与人工神经网络一样，训练不完善的深度神经网络中可能会出现许多问题。两个常见的问题是过拟合和计算时间。DNN倾向于过拟合，因为增加了抽象层，允许它们对训练数据中罕见的依赖关系建模。正则化方法如Ivakhnenko的单元剪枝[29]或者权重衰减（
关键词: 深度学习, 卷积神经网络, 循环神经网络, 人工神经网络
AI技术: 深度学习,  卷积神经网络,  循环神经网络,  长短期记忆网络,  深度信念网络
行业: 深度学习被广泛应用于以下行业：

1. 计算机视觉
2. 语音识别
3. 自然语言处理
重大事件摘要: 这篇文章主要概述了深度学习的历史、发展、应用和未来趋势。以下是文章中的重大事件总结：

1. 深度学习的引入：Rina Dechter在1986年将深度学习引入机器学习社区，而Igor Aizenberg和Geoffrey Hinton在2000年引入布尔阈值神经元下的深度神经网络。

2. 深度学习架构的发展：自1980年起，为计算机视觉构建的深度学习架构包括深度信念网络、循环神经网络、深度卷积神经网络等。这些架构在计算机视觉、语音识别、自然语言处理等领域取得了显著成果。

3. 深度学习革命：2012年，Alex Krizhevsky等人利用深度卷积神经网络在ImageNet竞赛中取得突破性成绩，标志着深度学习革命的开始。此后，深度学习在图像识别、语音识别等领域取得了显著进展。

4. 深度学习的应用：深度学习已广泛应用于计算机视觉、语音识别、自然语言处理、生物信息学、药物发现、医学图像分析、材料检查和棋盘游戏等领域。

5. 深度学习的未来趋势：随着硬件的发展（如GPU加速）和算法优化，深度学习将继续在各个领域取得突破。此外，深度学习与人类认知大脑发育的关系、商业活动以及与人类认知大脑发育的关系等方面的研究也将得到关注。
