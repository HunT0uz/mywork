标题: AI必须被人类管起来?专家们表示,大胆点,拥抱新技术
链接: http://baijiahao.baidu.com/s?id=1770748363810669981&wfr=spider&for=pc
总结: 生成式人工智能最近迎来“火箭式”发展，它也顺理成章成为本次世界人工智能大会绕不开的最热话题。香港科技大学首席副校长郭毅可现场开玩笑说，整个大会似乎都变成了“世界chatgpt会议”。生成式人工智能在大幅解放生产力的同时，安全、合法、道德、伦理等问题如何规范？7月7日，2023世界人工智能大会智能社会论坛在杨浦滨江举行。论坛以“智能社会与数字治理生态”为主题，与会中外专家学者对这些问题进行深入探讨，并发布了《人工智能大模型伦理规范操作指引》《生成式人工智能风险评估框架（1.0）》等一批专题研究成果。平衡ai发展和安全人工智能技术的益处不必赘述，与会专家基本都认可：它可以加速科学技术创新进步、刺激生产力和经济增长……但专家们也都认为，ai技术的风险不容忽视。联合国教科文组织社会科学及人文科学部门助理总干事加布里埃拉·拉莫斯在视频致辞中提到，ai技术会复制放大歧视，进而加深社会不平等；对环境的影响也不容忽视，大模型产生的二氧化碳排放量相当于125次往返北京纽约的航班；大型语言模型还会产生大量错误和虚假信息。关键在于平衡发展和安全。清华大学智能社会治理研究院院长苏竣从ai与环保角度切入举例：“目前数字化与绿色化发展之间还存在夹角，如果处理得当，智能技术将在推动能源生产消费革命方面发挥巨大作用，大幅降低能源消耗和碳排放，有助于尽快实现‘双碳’目标。反之，处理不当则可能带来更多能源消耗和社会福利的损失，使社会陷入生态危机。”“为了有效平衡发展和安全，探索人工智能的治理框架，已经成为国际社会的共识。”市教育委员会副主任叶霖霖介绍，欧盟的人工智能立法工作已经取得了长足进展，中国国家网信办也起草了生成式人工智能服务管理办法的征求意见稿。本次发布的《人工智能大模型伦理规范操作指引》（下简称“操作指引”）正是旨在应对人工智能大模型的风险，推动伦理规范落地实施。研究团队相关负责人、同济大学人文学院特聘教授杜严勇表示，大多数人工智能伦理原则和指南内容是趋同和重叠的，说明对于核心的人工智能伦理原则，基本已经取得了高度共识。但这些伦理原则如何落地实施，却始终没有较有力的措施，这也是尝试探讨人工智能大模型伦理规范操作指引的根本原因，“我们尽可能指向人工智能大模型技术特征以及可能的应用场景，提高操作指引的针对性。”“人类”必须在决策环中据介绍，操作指引把重点放在了人工智能的研发环节。研究团队认为，科研人员在人工智能伦理方面承担着最为重要的道德责任。值得注意的是，操作指引着重强调了“人类”的监督、控制和责任。“我们认为可以在一定程度上使人工智能大模型的决策和人类利益和价值观保持一致，这也是实现人工智能大模型安全性最为重要的方面。”杜严勇说，“无论人工智能大模型的伦理再强大，毕竟还是拥有工具属性。因此，我们一定要保证，在重大决策方面，‘人类’必须在决策环中。人工智能大模型必须处于人类监督和控制之下。”为此，操作指引提出，要通过完善责任内容分配，形成责任闭环，从而尽可能规避所谓的责任鸿沟和有组织的不负责任的现象。郭毅可也认为，人工智能风险管理中最重要的问题是，当ai通过不可思议的技术手段“复刻”了人类的表现，可能扰乱人类的认知，让人类误以为聊天机器人是“以人类的方式思考”，继而引发一系列后果。而实际上，人工智能只是表现得像人，“思考”过程更像个“黑箱”。郭毅可讲述了电影《她》的故事：男主角和妻子离婚后非常沮丧，开始和一个类似chatgpt的计算机聊天。计算机模拟的女声非常好听，又表现得温柔而幽默。男主角一发不可收拾地爱上了ai，最后却发现，ai对每个人都会例行公事地温柔幽默。如果说ai的“她”能算爱上了男主角，那“她”也同时爱上了好多好多人。这种认知的差异最终摧毁了男主角的心理。“这部电影对今天的情况作出了精准的预言。”郭毅可说，“我们治理ai，首先要让人懂机器，让机器懂人，让机器和人同理共情，这样的治理才会有坚实的科学基础。”要管，更要敢试敢闯不过，杜严勇等专家也都强调，对ai的治理（或管理）并非要阻碍或禁止ai技术发展，“这是谁也做不到的。”北京大学人工智能研究院研究员沈体雁说，ai治理主要就是三个问题，把ai创好、把ai用好、把ai管好，“后两方面，中国有绝对的优势。但在原始创新方面，我们还是有一些短板。”他建议，应该给ai研发者一点空间，对他们有更多的包容，“尽量少管他们，随便他们折腾。折腾出成果，再想办法管理。”“我们不能采取鸵鸟政策，更不能采取封堵政策，不要担心技术不可控，就选择不使用或者少使用。”苏竣说，“科学技术的大门已经打开了，应该勇敢站到舞台上去，采取积极治理措施去拥抱新技术，全面加强基于chatgpt架构的应用。”他提到，杨浦区是全国首批十个国家智能社会治理实验综合基地之一，更应该先行先试、不断探索，不断进入无人区，不断进入以前从没有过的新的ai技术的应用场景，推动更多技术应用，让新技术更好服务高质量发展。市委网信办信息化协调处处长单滨也认为，杨浦承担着为上海乃至全国智能治理抓试点、闯新路、出经验的使命。记者从杨浦区获悉，杨浦正紧密结合城市更新、数字化转型实际推进场景建设与实验研究，初步形成了应用主体“出题”，研究主体和技术主体“答题”的社会实验模式。今年以来，根据中央网信办有关要求，杨浦聚焦chatgpt等生成式人工智能大模型技术带来的机遇与挑战，联合哔哩哔哩等企业开展社会实验研究。除了当天会上发布的《生成式人工智能风险评估框架（1.0）》初步研究成果，杨浦还揭牌了“人工智能合规服务中心”。中心将充分发挥同济大学的智力与技术资源优势与杨浦区的实践优势，为企业的人工智能新技术新应用提供合规指引和咨询服务。杨浦区常务副区长尼冰表示，杨浦将深入分析区域经济、社会生活领域中的热点、痛点，不断提出问题、开展实践，建设一批企业和群众真正感到管用、好用、爱用的场景。打造出一批“人无我有，人有我优”的示范性项目，率先形成若干优势明显的展示窗口，并将研究成果及时转化为政策、标准、规范、举措，把更多文章转化为文件，为智能社会的治理提供更多上海示范、全国模板。栏目主编：唐烨本文作者：胡幸阳题图来源：朱瓅 设计
关键词: 生成式人工智能,  伦理规范,  风险评估,  数字治理
AI技术: 生成式人工智能, chatgpt, 大模型, 数字化与绿色化发展, 智能社会治理实验综合基地
行业: 教育,  科技 环保
重大事件摘要: 这篇文章报道了2023年世界人工智能大会智能社会论坛在上海杨浦滨江举行的相关情况。以下是文章中的重大事件总结：

1. **生成式人工智能的“火箭式”发展**：生成式人工智能成为本次世界人工智能大会的最热话题，香港科技大学首席副校长郭毅可开玩笑说整个大会似乎变成了“世界ChatGPT会议”。

2. **发布重要研究成果**：
   - 《人工智能大模型伦理规范操作指引》
   - 《生成式人工智能风险评估框架（1.0）》

3. **平衡AI发展和安全**：与会专家讨论了如何在促进AI技术发展的同时，确保其安全性和道德性。例如，联合国教科文组织助理总干事加布里埃拉·拉莫斯提到AI技术可能复制和放大歧视，增加社会不平等。

4. **环保与AI的关系**：清华大学智能社会治理研究院院长苏竣提到，如果处理得当，智能技术可以大幅降低能源消耗和碳排放，有助于实现“双碳”目标；反之则可能带来更多能源消耗和社会福利的损失。

5. **欧盟和中国在AI立法方面的进展**：欧盟的人工智能立法工作取得长足进展，中国国家网信办也起草了生成式人工智能服务管理办法的征求意见稿。

6. **人类必须在决策环中**：研究团队强调科研人员在AI伦理方面承担重要责任，并着重强调“人类”的监督、控制和责任，以确保AI大模型的安全性。

7. **电影《她》的故事作为警示**：郭毅可通过电影《她》的故事提醒人们，AI只是表现得像人，其“思考”过程更像个“黑箱”，需要谨慎对待。

8. **对AI治理的建议**：北京大学人工智能研究院研究员沈体雁建议给AI研发者更多空间和包容，尽量少管他们，折腾出成果后再管理。

9. **积极拥抱新技术**：苏竣认为应该勇敢站到舞台上去，采取积极治理措施拥抱新技术，推动更多技术应用。

10. **杨浦区的社会实验模式**：杨浦区结合城市更新和数字化转型推进场景建设与实验研究，形成应用主体“出题”，研究主体和技术主体“答题”的社会实验模式。

11. **成立“人工智能合规服务中心”**：杨浦区揭牌成立了“人工智能合规服务中心”，为企业提供合规指引和咨询服务。

12. **杨浦区的示范项目**：杨浦区将深入分析区域经济和社会生活中的热点和痛点，建设一批企业和群众真正感到管用、好用、爱用的场景，形成若干优势明显的展示窗口，并将研究成果转化为政策、标准、规范和举措。
