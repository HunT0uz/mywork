标题: 《生成式人工智能》作者丁磊:模型既要大也要深,有算力不一定能...
链接: https://baijiahao.baidu.com/s?id=1774464891362741680&wfr=spider&for=pc
总结: 界面新闻记者 | 于浩界面新闻编辑 | 2022年末，ChatGPT3.5的出现迅速引发了对大语言模型、生成式人工智能等概念的广泛探讨，AI大模型所展现的通识与逻辑能力似乎让人类离通用人工智能（AGI）更近了一步。在面向未来的设想中，作为人工智能的高阶形态，通用人工智能具备与人类同等智慧或超越人类智慧，能够为各个垂直领域带来深刻影响。 但聚焦于当下，具备多模态能力的大模型如何更好地落地仍在探索当中。一方面，如百度、科大讯飞、商汤、百川智能等科技企业纷纷跑步入场，发布了自己的大模型产品；另一方面，这一新型生产力工具似乎仍未出现现象级的落地案例。一位大模型生态应用层产品负责人曾告诉界面新闻，接入大模型改变了原有交互或软件底层架构的构建形式，以及之前的API和数据存储的方式，这对于接入大模型公司而言都是必须面对的课题。除了数字化基座的改造之外，大模型的应用层搭建还要面临各家底层芯片的适配等问题。据《生成式人工智能》作者丁磊判断，在千亿大模型基础上微调出来的行业深模型是最终解决方案。丁磊是美国俄亥俄州立大学人工智能专业博士，美国哥伦比亚大学博士后，持有斯坦福大学高级项目管理证书。但他的身份并非单纯的学者，此前他曾任PayPal人工智能平台负责人、百度金融首席数据科学家等高级职务，并曾在IBM Watson研究院和美国伊利诺伊大学贝克曼研究所从事研究工作。“因为大模型的发散性是没法解决的，所以必须要通过恰当的微调形成行业专用的深模型。”在他看来，行业深模型未必是小模型，参数规模大小要看应用场景的需要。当场景中交流相对封闭、不需要太多逻辑和通识时，小模型也足以满足需求。在其新书《生成式人工智能》中，丁磊也列举了生成式人工智能在生产制造、供应链管理、市场营销、客户服务等方面的商业模落地案例及其场景。针对大模型落地过程中应当如何看待人工智能安全问题、行业深模型如何构建、在哪些场景适合落地等问题，界面新闻与丁磊进行了对谈。 界面新闻：你在书中提及，在迈向AGI的过程当中，迁移学习和领域自身的能力是两个重要研究方向，人工智能以这样的思路去做学习的过程中，是否会产生认知局限？丁磊：类似于人脑是人思维的载体，人工智能也要通过模型来进行思考。模型是知识和逻辑的数字化载体，此前也尝试过用别的方式来表达知识和逻辑，但是模型是最成功的一种数字化载体。至于是否会形成刻板印象相关的局限性，可以从模型的角度来进行解释。数据、模型、算力、业务模型作为人工智能的四个要素，决定AI如何超出上述局限性，模型是最核心的要素。人类也是通过现有经验学习规律，生成式AI也完全可以生成新图片。在通常意义上的创造性，我认为AI是具备的，但是更深层次的科学、艺术方面就未必能胜任了。 界面新闻：控制论中曾提及，任何有效的控制系统都必须和它控制的系统一样复杂。当我们走过AGI迈向超人智能的过程中，应当如何看待人工智能安全的问题？丁磊：从模型角度来进行解释，面对一个决策或者生成内容，它都是以概率形式来进行考虑的。多少概率下自动驾驶汽车需要停下来，或者是在其他的场景中做出相应的反应，这个阈值的设定是有人为因素的。如果概率比较低，它就认为事情不会发生，其中就必然存在折中的阈值，这里面就会涉及到决策的伦理问题。AI的学习都是在统计意义上的学习，也就是说对于整体的数据样本它的决策是合理的，但具体到单一数据的时候就可能会做出边界模糊的决策。因此我们需要在人机之外规定好折中的合理性，如果没有这样的共识的话，概率的可信或者不可信就无法被定义。界面新闻：有关书中提及从AIGC到AGI的超级计算能力，除了芯片的升级迭代之外，在算法方面是否会有优化和突破的空间？丁磊：模型结构的完善和提升肯定会有帮助。算力只是一方面，如果模型的结构不适合数据，或者说训练的方法不对，再多的算力也没用。就像工业生产中如果设备本身有问题，往里面输送再多的电能也没有用。所以我也提出深模型的概念，模型不光要大，它还要深，能够理解场景内的业务问题。恰当的网络结构、训练方法、数据才能带来深模型，“只要有算力就能带来突破”这种传统观念，我觉得是有些偏颇的。 界面新闻：如ChatGPT、讯飞星火都打出了搭建生态的口号，开放大模型开发接口。这种生态化的尝试在推进模型迭代、商业化进程方面各自有哪些意义？丁磊：对于这种模型来说，开放接口是IT层面的比较初级的事，更主要的目的还是模型的学习和迭代。模型本身逐渐适应商业场景并且逐步提升效果，这叫模型的迭代。举个例子，ChatGPT有很多插件和应用程序，这相当于眼睛和耳朵，使得ChatGPT能直接从应用里面拉取数据帮助它进行学习迭代。我觉得最终的生态肯定是向这个方向发展，如果说我有一个模型生态，然后给人调用了，其实并不一定代表他具有学习和演化的能力。若没有很好的构造这个场景的话，模型是没有办法自己去学习了解的。界面新闻：用大语料库训练的通用大模型与用专有语料库训练的专用小模型，两者之间是否能够并行？你对两种思路的看法是怎样的？丁磊：我认为在千亿大模型基础上微调出来的行业深模型是最终解决方案。因为大模型的发散性是没法解决的，必须要通过恰当的微调形成行业专用的深模型。怎么在使用大模型的逻辑能力和通识的同时限制住大模型，使它能够在面对问题时回答知识库中已有的答案，这是目前前沿研究的一些课题。行业深模型未必是小模型，关键要看应用场景的需要，有的场景的交流可能是比较封闭的，不需要太多逻辑和通识，小模型就够了，但是更多场景需要的是又大又深的模型。 界面新闻：如何评判场景里是否适合深模型投入使用？丁磊：主要有四个条件，一个是人做不了的，比如做广告推荐，每天可能有上千万上亿的用户，这不可能让人去做；第二个是人做不好的，之前用大数据做金融风控，数据上可评价的维度特别多，人如果只通过一些简单的维度来判断信用问题可能不够准确；第三个是人效率低的，比说一些基础的文案和图片创作的工作；最后就是人不稳定的，比如在工业质检场景，人也可以做，但人不一定具有这么高的稳定性。 界面新闻：你在《AI思维：从数据中创造价值的炼金术》一书中曾强调要有数据化驱动的思维。这一能力是否会造成素养鸿沟的加大？如何看待AI与数字鸿沟之间的关系？丁磊：向ChatGPT提问、说AI的语言，最终的底层逻辑都是AI思维，是一种基于数据训练模型的思维能力。随着AI使用范围的加大，有人会更快更好地接受了AI，效率会提升。如果没法接受AI的改进可能就会在时代潮流中落后。那么我觉得是会形成所谓的这种数字化鸿沟的。但是AI只是一种工具，取代人的永远会是别的人。普华永道的报告指出，人工智能及相关技术在未来20年将取代中国现有约26%的工作岗位，也会产生38%的新的岗位，最终会净增12%的工作岗位，为社会带来的只会是职业结构性的影响。人工智能不是竞争对手，是工作伙伴，我们就要学会训练人工智能和使用人工智能，让人工智能为我们所用，与人工智能一起工作。界面新闻记者 | 于浩界面新闻编辑 | 2022年末，ChatGPT3.5的出现迅速引发了对大语言模型、生成式人工智能等概念的广泛探讨，AI大模型所展现的通识与逻辑能力似乎让人类离通用人工智能（AGI）更近了一步。2022年末，ChatGPT3.5的出现迅速引发了对大语言模型、生成式人工智能等概念的广泛探讨，AI大模型所展现的通识与逻辑能力似乎让人类离通用人工智能（AGI）更近了一步。在面向未来的设想中，作为人工智能的高阶形态，通用人工智能具备与人类同等智慧或超越人类智慧，能够为各个垂直领域带来深刻影响。 在面向未来的设想中，作为人工智能的高阶形态，通用人工智能具备与人类同等智慧或超越人类智慧，能够为各个垂直领域带来深刻影响。但聚焦于当下，具备多模态能力的大模型如何更好地落地仍在探索当中。一方面，如百度、科大讯飞、商汤、百川智能等科技企业纷纷跑步入场，发布了自己的大模型产品；另一方面，这一新型生产力工具似乎仍未出现现象级的落地案例。但聚焦于当下，具备多模态能力的大模型如何更好地落地仍在探索当中。一方面，如百度、科大讯飞、商汤、百川智能等科技企业纷纷跑步入场，发布了自己的大模型产品；另一方面，这一新型生产力工具似乎仍未出现现象级的落地案例。一位大模型生态应用层产品负责人曾告诉界面新闻，接入大模型改变了原有交互或软件底层架构的构建形式，以及之前的API和数据存储的方式，这对于接入大模型公司而言都是必须面对的课题。除了数字化基座的改造之外，大模型的应用层搭建还要面临各家底层芯片的适配等问题。一位大模型生态应用层产品负责人曾告诉界面新闻，接入大模型改变了原有交互或软件底层架构的构建形式，以及之前的API和数据存储的方式，这对于接入大模型公司而言都是必须面对的课题。除了数字化基座的改造之外，大模型的应用层搭建还要面临各家底层芯片的适配等问题。据《生成式人工智能》作者丁磊判断，在千亿大模型基础上微调出来的行业深模型是最终解决方案。丁磊是美国俄亥俄州立大学人工智能专业博士，美国哥伦比亚大学博士后，持有斯坦福大学高级项目管理证书。但他的身份并非单纯的学者，此前他曾任PayPal人工智能平台负责人、百度金融首席数据科学家等高级职务，并曾在IBM Watson研究院和美国伊利诺伊大学贝克曼研究所从事研究工作。据《生成式人工智能》作者丁磊判断，在千亿大模型基础上微调出来的行业深模型是最终解决方案。丁磊是美国俄亥俄州立大学人工智能专业博士，美国哥伦比亚大学博士后，持有斯坦福大学高级项目管理证书。但他的身份并非单纯的学者，此前他曾任PayPal人工智能平台负责人、百度金融首席数据科学家等高级职务，并曾在IBM Watson研究院和美国伊利诺伊大学贝克曼研究所从事研究工作。“因为大模型的发散性是没法解决的，所以必须要通过恰当的微调形成行业专用的深模型。”在他看来，行业深模型未必是小模型，参数规模大小要看应用场景的需要。当场景中交流相对封闭、不需要太多逻辑和通识时，小模型也足以满足需求。“因为大模型的发散性是没法解决的，所以必须要通过恰当的微调形成行业专用的深模型。”在他看来，行业深模型未必是小模型，参数规模大小要看应用场景的需要。当场景中交流相对封闭、不需要太多逻辑和通识时，小模型也足以满足需求。在其新书《生成式人工智能》中，丁磊也列举了生成式人工智能在生产制造、供应链管理、市场营销、客户服务等方面的商业模落地案例及其场景。针对大模型落地过程中应当如何看待人工智能安全问题、行业深模型如何构建、在哪些场景适合落地等问题，界面新闻与丁磊进行了对谈。 在其新书《生成式人工智能》中，丁磊也列举了生成式人工智能在生产制造、供应链管理、市场营销、客户服务等方面的商业模落地案例及其场景。针对大模型落地过程中应当如何看待人工智能安全问题、行业深模型如何构建、在哪些场景适合落地等问题，界面新闻与丁磊进行了对谈。以下为专访摘要：以下为专访摘要：界面新闻：你在书中提及，在迈向AGI的过程当中，迁移学习和领域自身的能力是两个重要研究方向，人工智能以这样的思路去做学习的过程中，是否会产生认知局限？丁磊：类似于人脑是人思维的载体，人工智能也要通过模型来进行思考。模型是知识和逻辑的数字化载体，此前也尝试过用别的方式来表达知识和逻辑，但是模型是最成功的一种数字化载体。至于是否会形成刻板印象相关的局限性，可以从模型的角度来进行解释。数据、模型、算力、业务模型作为人工智能的四个要素，决定AI如何超出上述局限性，模型是最核心的要素。丁磊：类似于人脑是人思维的载体，人工智能也要通过模型来进行思考。模型是知识和逻辑的数字化载体，此前也尝试过用别的方式来表达知识和逻辑，但是模型是最成功的一种数字化载体。至于是否会形成刻板印象相关的局限性，可以从模型的角度来进行解释。数据、模型、算力、业务模型作为人工智能的四个要素，决定AI如何超出上述局限性，模型是最核心的要素。人类也是通过现有经验学习规律，生成式AI也完全可以生成新图片。在通常意义上的创造性，我认为AI是具备的，但是更深层次的科学、艺术方面就未必能胜任了。 人类也是通过现有经验学习规律，生成式AI也完全可以生成新图片。在通常意义上的创造性，我认为AI是具备的，但是更深层次的科学、艺术方面就未必能胜任了。界面新闻：控制论中曾提及，任何有效的控制系统都必须和它控制的系统一样复杂。当我们走过AGI迈向超人智能的过程中，应当如何看待人工智能安全的问题？丁磊：从模型角度来进行解释，面对一个决策或者生成内容，它都是以概率形式来进行考虑的。多少概率下自动驾驶汽车需要停下来，或者是在其他的场景中做出相应的反应，这个阈值的设定是有人为因素的。如果概率比较低，它就认为事情不会发生，其中就必然存在折中的阈值，这里面就会涉及到决策的伦理问题。丁磊：从模型角度来进行解释，面对一个决策或者生成内容，它都是以概率形式来进行考虑的。多少概率下自动驾驶汽车需要停下来，或者是在其他的场景中做出相应的反应，这个阈值的设定是有人为因素的。如果概率比较低，它就认为事情不会发生，其中就必然存在折中的阈值，这里面就会涉及到决策的伦理问题。AI的学习都是在统计意义上的学习，也就是说对于整体的数据样本它的决策是合理的，但具体到单一数据的时候就可能会做出边界模糊的决策。因此我们需要在人机之外规定好折中的合理性，如果没有这样的共识的话，概率的可信或者不可信就无法被定义。AI的学习都是在统计意义上的学习，也就是说对于整体的数据样本它的决策是合理的，但具体到单一数据的时候就可能会做出边界模糊的决策。因此我们需要在人机之外规定好折中的合理性，如果没有这样的共识的话，概率的可信或者不可信就无法被定义。界面新闻：有关书中提及从AIGC到AGI的超级计算能力，除了芯片的升级迭代之外，在算法方面是否会有优化和突破的空间？丁磊：模型结构的完善和提升肯定会有帮助。算力只是一方面，如果模型的结构不适合数据，或者说训练的方法不对，再多的算力也没用。就像工业生产中如果设备本身有问题，往里面输送再多的电能也没有用。丁磊：模型结构的完善和提升肯定会有帮助。算力只是一方面，如果模型的结构不适合数据，或者说训练的方法不对，再多的算力也没用。就像工业生产中如果设备本身有问题，往里面输送再多的电能也没有用。所以我也提出深模型的概念，模型不光要大，它还要深，能够理解场景内的业务问题。恰当的网络结构、训练方法、数据才能带来深模型，“只要有算力就能带来突破”这种传统观念，我觉得是有些偏颇的。 所以我也提出深模型的概念，模型不光要大，它还要深，能够理解场景内的业务问题。恰当的网络结构、训练方法、数据才能带来深模型，“只要有算力就能带来突破”这种传统观念，我觉得是有些偏颇的。界面新闻：如ChatGPT、讯飞星火都打出了搭建生态的口号，开放大模型开发接口。这种生态化的尝试在推进模型迭代、商业化进程方面各自有哪些意义？丁磊：对于这种模型来说，开放接口是IT层面的比较初级的事，更主要的目的还是模型的学习和迭代。模型本身逐渐适应商业场景并且逐步提升效果，这叫模型的迭代。举个例子，ChatGPT有很多插件和应用程序，这相当于眼睛和耳朵，使得ChatGPT能直接从应用里面拉取数据帮助它进行学习迭代。丁磊：对于这种模型来说，开放接口是IT层面的比较初级的事，更主要的目的还是模型的学习和迭代。模型本身逐渐适应商业场景并且逐步提升效果，这叫模型的迭代。举个例子，ChatGPT有很多插件和应用程序，这相当于眼睛和耳朵，使得ChatGPT能直接从应用里面拉取数据帮助它进行学习迭代。我觉得最终的生态肯定是向这个方向发展，如果说我有一个模型生态，然后给人调用了，其实并不一定代表他具有学习和演化的能力。若没有很好的构造这个场景的话，模型是没有办法自己去学习了解的。我觉得最终的生态肯定是向这个方向发展，如果说我有一个模型生态，然后给人调用了，其实并不一定代表他具有学习和演化的能力。若没有很好的构造这个场景的话，模型是没有办法自己去学习了解的。界面新闻：用大语料库训练的通用大模型与用专有语料库训练的专用小模型，两者之间是否能够并行？你对两种思路的看法是怎样的？丁磊：我认为在千亿大模型基础上微调出来的行业深模型是最终解决方案。因为大模型的发散性是没法解决的，必须要通过恰当的微调形成行业专用的深模型。怎么在使用大模型的逻辑能力和通识的同时限制住大模型，使它能够在面对问题时回答知识库中已有的答案，这是目前前沿研究的一些课题。丁磊：我认为在千亿大模型基础上微调出来的行业深模型是最终解决方案。因为大模型的发散性是没法解决的，必须要通过恰当的微调形成行业专用的深模型。怎么在使用大模型的逻辑能力和通识的同时限制住大模型，使它能够在面对问题时回答知识库中已有的答案，这是目前前沿研究的一些课题。行业深模型未必是小模型，关键要看应用场景的需要，有的场景的交流可能是比较封闭的，不需要太多逻辑和通识，小模型就够了，但是更多场景需要的是又大又深的模型。 行业深模型未必是小模型，关键要看应用场景的需要，有的场景的交流可能是比较封闭的，不需要太多逻辑和通识，小模型就够了，但是更多场景需要的是又大又深的模型。界面新闻：如何评判场景里是否适合深模型投入使用？丁磊：主要有四个条件，一个是人做不了的，比如做广告推荐，每天可能有上千万上亿的用户，这不可能让人去做；第二个是人做不好的，之前用大数据做金融风控，数据上可评价的维度特别多，人如果只通过一些简单的维度来判断信用问题可能不够准确；第三个是人效率低的，比说一些基础的文案和图片创作的工作；最后就是人不稳定的，比如在工业质检场景，人也可以做，但人不一定具有这么高的稳定性。 丁磊：主要有四个条件，一个是人做不了的，比如做广告推荐，每天可能有上千万上亿的用户，这不可能让人去做；第二个是人做不好的，之前用大数据做金融风控，数据上可评价的维度特别多，人如果只通过一些简单的维度来判断信用问题可能不够准确；第三个是人效率低的，比说一些基础的文案和图片创作的工作；最后就是人不稳定的，比如在工业质检场景，人也可以做，但人不一定具有这么高的稳定性。界面新闻：你在《AI思维：从数据中创造价值的炼金术》一书中曾强调要有数据化驱动的思维。这一能力是否会造成素养鸿沟的加大？如何看待AI与数字鸿沟之间的关系？丁磊：向ChatGPT提问、说AI的语言，最终的底层逻辑都是AI思维，是一种基于数据训练模型的思维能力。随着AI使用范围的加大，有人会更快更好地接受了AI，效率会提升。如果没法接受AI的改进可能就会在时代潮流中落后。那么我觉得是会形成所谓的这种数字化鸿沟的。丁磊：向ChatGPT提问、说AI的语言，最终的底层逻辑都是AI思维，是一种基于数据训练模型的思维能力。随着AI使用范围的加大，有人会更快更好地接受了AI，效率会提升。如果没法接受AI的改进可能就会在时代潮流中落后。那么我觉得是会形成所谓的这种数字化鸿沟的。但是AI只是一种工具，取代人的永远会是别的人。普华永道的报告指出，人工智能及相关技术在未来20年将取代中国现有约26%的工作岗位，也会产生38%的新的岗位，最终会净增12%的工作岗位，为社会带来的只会是职业结构性的影响。人工智能不是竞争对手，是工作伙伴，我们就要学会训练人工智能和使用人工智能，让人工智能为我们所用，与人工智能一起工作。但是AI只是一种工具，取代人的永远会是别的人。普华永道的报告指出，人工智能及相关技术在未来20年将取代中国现有约26%的工作岗位，也会产生38%的新的岗位，最终会净增12%的工作岗位，为社会带来的只会是职业结构性的影响。人工智能不是竞争对手，是工作伙伴，我们就要学会训练人工智能和使用人工智能，让人工智能为我们所用，与人工智能一起工作。举报/反馈
关键词: 生成式人工智能, 大模型, 深模型
AI技术: 生成式人工智能, 大语言模型, 深度学习
行业: 金融, 大数据, 人工智能
重大事件摘要: 这篇文章主要讨论了生成式人工智能（AI）的发展趋势、应用落地、行业模型的重要性以及人工智能安全等问题。以下是文章中提到的重大事件和要点：

1. **大模型的发展和应用探索**：随着ChatGPT3.5的出现，引发了对大语言模型和生成式人工智能概念的广泛讨论。这些技术展现了强大的通识与逻辑能力，为通用人工智能（AGI）的发展提供了可能。

2. **多模态能力的大模型落地挑战**：尽管具备多模态能力的大模型被视为新型生产力工具，但如何有效落地并应用于各个垂直领域仍面临挑战。目前尚未出现现象级的落地案例。

3. **行业深模型作为解决方案**：丁磊提出，基于千亿大模型微调的行业深模型是最终解决方案。这种模型旨在解决大模型的发散性问题，通过恰当的微调形成行业专用的深模型。

4. **大模型落地过程中的挑战**：接入大模型改变了原有交互或软件底层架构的构建形式，以及API和数据存储的方式。此外，还需要解决数字化基座改造和各家底层芯片的适配问题。

5. **人工智能安全问题**：从模型角度考虑，面对决策或生成内容时，是以概率形式进行考虑的。因此，需要规定人机之外的折中合理性，以处理决策的伦理问题。

6. **算法优化和突破的可能性**：除了芯片升级迭代外，模型结构的完善和提升也将有助于提高性能。提出深模型的概念，强调模型不仅要大，还要深，能够理解场景内的业务问题。

7. **生态化尝试的意义**：如ChatGPT、讯飞星火等开放大模型开发接口，推进模型迭代和商业化进程。这种生态化的尝试对于模型学习和演化具有重要意义。

8. **大模型与小模型的并行可能性**：讨论了用大语料库训练的通用大模型与用专有语料库训练的专用小模型之间的并行可能性。认为在千亿大模型基础上微调出来的行业深模型是最终解决方案。

9. **评判场景适合深模型的条件**：提出了四个条件来判断场景是否适合深模型投入使用：人做不了的、人做不好的、人效率低的、人不稳定的。

10. **数据化驱动的思维与素养鸿沟**：强调了AI思维的重要性，认为随着AI使用范围的加大，会形成数字化鸿沟。但同时指出，AI不是竞争对手，而是工作伙伴。
